{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = np.loadtxt('./GSE107011_Processed_data_TPM.txt', skiprows = 1,dtype=str, unpack = True)\n",
    "# a = np.genfromtxt('./GSE107011_Processed_data_TPM.txt', names = True, dtype = None, unpack = False, encoding='ascii')\n",
    "# Todo: read the head(sample name) directly as index\n",
    "a = np.loadtxt('./GSE107011_Processed_data_TPM.txt', dtype=float, skiprows=1, usecols=(range(1,128)), unpack=True)\n",
    "# data = torch.from_numpy(a)\n",
    "# data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "#         'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         'Generates one sample of data'\n",
    "        return torch.from_numpy(self.data[index])\n",
    "\n",
    "dataset = Dataset(a)\n",
    "train_loader = data.DataLoader(dataset=dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,loss_fn,data_loader=None,epochs=1,optimizer=None):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "        for batch_data in train_loader:\n",
    "            i+=1\n",
    "            batch_data = batch_data.type('torch.FloatTensor')\n",
    "            data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(data_loader.dataset),\n",
    "                100. * i / len(data_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(DeepAutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Linear(16384, 8192),\n",
    "#             nn.ReLU(True), \n",
    "            nn.Linear(2048,1024),\n",
    "#             nn.ReLU(True), \n",
    "            nn.Linear(1024, encoding_dim), \n",
    "#             nn.ReLU(True),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 1024),\n",
    "#             nn.ReLU(True),\n",
    "            nn.Linear(1024,2048),\n",
    "#             nn.ReLU(True), \n",
    "#             nn.Linear(8192,16384),\n",
    "#             nn.ReLU(True), \n",
    "            nn.Linear(2048, input_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(a[1])\n",
    "encoding_dim = 512\n",
    "\n",
    "model = DeepAutoEncoder(input_dim, encoding_dim)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [10/127 (8%)]\tLoss: 65536.570312\n",
      "Train Epoch: 0 [20/127 (15%)]\tLoss: 120474.703125\n",
      "Train Epoch: 0 [30/127 (23%)]\tLoss: 472959.500000\n",
      "Train Epoch: 0 [40/127 (31%)]\tLoss: 1081175.625000\n",
      "Train Epoch: 0 [50/127 (38%)]\tLoss: 236201.078125\n",
      "Train Epoch: 0 [60/127 (46%)]\tLoss: 223420.218750\n",
      "Train Epoch: 0 [70/127 (54%)]\tLoss: 3096361.000000\n",
      "Train Epoch: 0 [80/127 (62%)]\tLoss: 187904.390625\n",
      "Train Epoch: 0 [90/127 (69%)]\tLoss: 206500.078125\n",
      "Train Epoch: 0 [100/127 (77%)]\tLoss: 414051.250000\n",
      "Train Epoch: 0 [110/127 (85%)]\tLoss: 144082.890625\n",
      "Train Epoch: 0 [120/127 (92%)]\tLoss: 119869.398438\n",
      "Train Epoch: 0 [91/127 (100%)]\tLoss: 239062.859375\n",
      "Train Epoch: 1 [10/127 (8%)]\tLoss: 94807.015625\n",
      "Train Epoch: 1 [20/127 (15%)]\tLoss: 153219.796875\n",
      "Train Epoch: 1 [30/127 (23%)]\tLoss: 167711.781250\n",
      "Train Epoch: 1 [40/127 (31%)]\tLoss: 557839.125000\n",
      "Train Epoch: 1 [50/127 (38%)]\tLoss: 665184.187500\n",
      "Train Epoch: 1 [60/127 (46%)]\tLoss: 362702.375000\n",
      "Train Epoch: 1 [70/127 (54%)]\tLoss: 322370.031250\n",
      "Train Epoch: 1 [80/127 (62%)]\tLoss: 188714.390625\n",
      "Train Epoch: 1 [90/127 (69%)]\tLoss: 366131.937500\n",
      "Train Epoch: 1 [100/127 (77%)]\tLoss: 111510.156250\n",
      "Train Epoch: 1 [110/127 (85%)]\tLoss: 100907.757812\n",
      "Train Epoch: 1 [120/127 (92%)]\tLoss: 637486.187500\n",
      "Train Epoch: 1 [91/127 (100%)]\tLoss: 118892.554688\n",
      "Train Epoch: 2 [10/127 (8%)]\tLoss: 826471.062500\n",
      "Train Epoch: 2 [20/127 (15%)]\tLoss: 1409286.250000\n",
      "Train Epoch: 2 [30/127 (23%)]\tLoss: 186679.140625\n",
      "Train Epoch: 2 [40/127 (31%)]\tLoss: 101468.750000\n",
      "Train Epoch: 2 [50/127 (38%)]\tLoss: 330426.093750\n",
      "Train Epoch: 2 [60/127 (46%)]\tLoss: 122027.445312\n",
      "Train Epoch: 2 [70/127 (54%)]\tLoss: 116270.414062\n",
      "Train Epoch: 2 [80/127 (62%)]\tLoss: 270700.468750\n",
      "Train Epoch: 2 [90/127 (69%)]\tLoss: 253078.578125\n",
      "Train Epoch: 2 [100/127 (77%)]\tLoss: 92324.429688\n",
      "Train Epoch: 2 [110/127 (85%)]\tLoss: 173711.109375\n",
      "Train Epoch: 2 [120/127 (92%)]\tLoss: 547775.562500\n",
      "Train Epoch: 2 [91/127 (100%)]\tLoss: 306308.437500\n",
      "Train Epoch: 3 [10/127 (8%)]\tLoss: 93091.328125\n",
      "Train Epoch: 3 [20/127 (15%)]\tLoss: 216078.937500\n",
      "Train Epoch: 3 [30/127 (23%)]\tLoss: 109449.351562\n",
      "Train Epoch: 3 [40/127 (31%)]\tLoss: 121994.179688\n",
      "Train Epoch: 3 [50/127 (38%)]\tLoss: 181655.781250\n",
      "Train Epoch: 3 [60/127 (46%)]\tLoss: 135967.343750\n",
      "Train Epoch: 3 [70/127 (54%)]\tLoss: 198154.937500\n",
      "Train Epoch: 3 [80/127 (62%)]\tLoss: 183962.312500\n",
      "Train Epoch: 3 [90/127 (69%)]\tLoss: 104547.617188\n",
      "Train Epoch: 3 [100/127 (77%)]\tLoss: 169049.343750\n",
      "Train Epoch: 3 [110/127 (85%)]\tLoss: 105946.164062\n",
      "Train Epoch: 3 [120/127 (92%)]\tLoss: 155183.234375\n",
      "Train Epoch: 3 [91/127 (100%)]\tLoss: 99777.531250\n",
      "Train Epoch: 4 [10/127 (8%)]\tLoss: 85126.445312\n",
      "Train Epoch: 4 [20/127 (15%)]\tLoss: 122361.445312\n",
      "Train Epoch: 4 [30/127 (23%)]\tLoss: 181019.750000\n",
      "Train Epoch: 4 [40/127 (31%)]\tLoss: 46749.992188\n",
      "Train Epoch: 4 [50/127 (38%)]\tLoss: 112041.609375\n",
      "Train Epoch: 4 [60/127 (46%)]\tLoss: 53263.894531\n",
      "Train Epoch: 4 [70/127 (54%)]\tLoss: 39145.136719\n",
      "Train Epoch: 4 [80/127 (62%)]\tLoss: 75409.734375\n",
      "Train Epoch: 4 [90/127 (69%)]\tLoss: 51219.351562\n",
      "Train Epoch: 4 [100/127 (77%)]\tLoss: 55742.453125\n",
      "Train Epoch: 4 [110/127 (85%)]\tLoss: 71395.351562\n",
      "Train Epoch: 4 [120/127 (92%)]\tLoss: 65519.652344\n",
      "Train Epoch: 4 [91/127 (100%)]\tLoss: 56960.660156\n",
      "Train Epoch: 5 [10/127 (8%)]\tLoss: 34007.187500\n",
      "Train Epoch: 5 [20/127 (15%)]\tLoss: 128124.437500\n",
      "Train Epoch: 5 [30/127 (23%)]\tLoss: 100065.507812\n",
      "Train Epoch: 5 [40/127 (31%)]\tLoss: 21757.095703\n",
      "Train Epoch: 5 [50/127 (38%)]\tLoss: 77549.117188\n",
      "Train Epoch: 5 [60/127 (46%)]\tLoss: 51909.519531\n",
      "Train Epoch: 5 [70/127 (54%)]\tLoss: 25577.167969\n",
      "Train Epoch: 5 [80/127 (62%)]\tLoss: 56597.910156\n",
      "Train Epoch: 5 [90/127 (69%)]\tLoss: 33837.472656\n",
      "Train Epoch: 5 [100/127 (77%)]\tLoss: 34037.023438\n",
      "Train Epoch: 5 [110/127 (85%)]\tLoss: 31080.105469\n",
      "Train Epoch: 5 [120/127 (92%)]\tLoss: 71751.476562\n",
      "Train Epoch: 5 [91/127 (100%)]\tLoss: 34159.058594\n",
      "Train Epoch: 6 [10/127 (8%)]\tLoss: 22172.562500\n",
      "Train Epoch: 6 [20/127 (15%)]\tLoss: 42195.160156\n",
      "Train Epoch: 6 [30/127 (23%)]\tLoss: 31452.121094\n",
      "Train Epoch: 6 [40/127 (31%)]\tLoss: 18280.378906\n",
      "Train Epoch: 6 [50/127 (38%)]\tLoss: 58084.781250\n",
      "Train Epoch: 6 [60/127 (46%)]\tLoss: 21879.001953\n",
      "Train Epoch: 6 [70/127 (54%)]\tLoss: 12484.588867\n",
      "Train Epoch: 6 [80/127 (62%)]\tLoss: 42280.035156\n",
      "Train Epoch: 6 [90/127 (69%)]\tLoss: 19709.591797\n",
      "Train Epoch: 6 [100/127 (77%)]\tLoss: 24425.958984\n",
      "Train Epoch: 6 [110/127 (85%)]\tLoss: 18289.521484\n",
      "Train Epoch: 6 [120/127 (92%)]\tLoss: 39128.273438\n",
      "Train Epoch: 6 [91/127 (100%)]\tLoss: 19366.646484\n",
      "Train Epoch: 7 [10/127 (8%)]\tLoss: 12216.625000\n",
      "Train Epoch: 7 [20/127 (15%)]\tLoss: 36948.558594\n",
      "Train Epoch: 7 [30/127 (23%)]\tLoss: 26267.181641\n",
      "Train Epoch: 7 [40/127 (31%)]\tLoss: 11305.882812\n",
      "Train Epoch: 7 [50/127 (38%)]\tLoss: 45876.769531\n",
      "Train Epoch: 7 [60/127 (46%)]\tLoss: 18342.173828\n",
      "Train Epoch: 7 [70/127 (54%)]\tLoss: 9021.099609\n",
      "Train Epoch: 7 [80/127 (62%)]\tLoss: 27549.082031\n",
      "Train Epoch: 7 [90/127 (69%)]\tLoss: 16320.716797\n",
      "Train Epoch: 7 [100/127 (77%)]\tLoss: 19287.720703\n",
      "Train Epoch: 7 [110/127 (85%)]\tLoss: 12701.333008\n",
      "Train Epoch: 7 [120/127 (92%)]\tLoss: 28289.724609\n",
      "Train Epoch: 7 [91/127 (100%)]\tLoss: 15666.046875\n",
      "Train Epoch: 8 [10/127 (8%)]\tLoss: 9202.380859\n",
      "Train Epoch: 8 [20/127 (15%)]\tLoss: 25027.373047\n",
      "Train Epoch: 8 [30/127 (23%)]\tLoss: 22044.001953\n",
      "Train Epoch: 8 [40/127 (31%)]\tLoss: 9545.969727\n",
      "Train Epoch: 8 [50/127 (38%)]\tLoss: 33500.566406\n",
      "Train Epoch: 8 [60/127 (46%)]\tLoss: 15500.154297\n",
      "Train Epoch: 8 [70/127 (54%)]\tLoss: 6942.001953\n",
      "Train Epoch: 8 [80/127 (62%)]\tLoss: 17912.052734\n",
      "Train Epoch: 8 [90/127 (69%)]\tLoss: 14520.939453\n",
      "Train Epoch: 8 [100/127 (77%)]\tLoss: 16311.878906\n",
      "Train Epoch: 8 [110/127 (85%)]\tLoss: 9543.643555\n",
      "Train Epoch: 8 [120/127 (92%)]\tLoss: 19410.541016\n",
      "Train Epoch: 8 [91/127 (100%)]\tLoss: 13353.572266\n",
      "Train Epoch: 9 [10/127 (8%)]\tLoss: 8363.746094\n",
      "Train Epoch: 9 [20/127 (15%)]\tLoss: 16405.691406\n",
      "Train Epoch: 9 [30/127 (23%)]\tLoss: 19420.234375\n",
      "Train Epoch: 9 [40/127 (31%)]\tLoss: 8339.742188\n",
      "Train Epoch: 9 [50/127 (38%)]\tLoss: 24401.492188\n",
      "Train Epoch: 9 [60/127 (46%)]\tLoss: 13792.916016\n",
      "Train Epoch: 9 [70/127 (54%)]\tLoss: 6435.452148\n",
      "Train Epoch: 9 [80/127 (62%)]\tLoss: 13059.441406\n",
      "Train Epoch: 9 [90/127 (69%)]\tLoss: 13476.337891\n",
      "Train Epoch: 9 [100/127 (77%)]\tLoss: 14941.238281\n",
      "Train Epoch: 9 [110/127 (85%)]\tLoss: 8291.421875\n",
      "Train Epoch: 9 [120/127 (92%)]\tLoss: 16043.158203\n",
      "Train Epoch: 9 [91/127 (100%)]\tLoss: 12398.023438\n",
      "Train Epoch: 10 [10/127 (8%)]\tLoss: 7889.176270\n",
      "Train Epoch: 10 [20/127 (15%)]\tLoss: 12907.469727\n",
      "Train Epoch: 10 [30/127 (23%)]\tLoss: 16910.548828\n",
      "Train Epoch: 10 [40/127 (31%)]\tLoss: 7778.868652\n",
      "Train Epoch: 10 [50/127 (38%)]\tLoss: 20618.199219\n",
      "Train Epoch: 10 [60/127 (46%)]\tLoss: 12417.609375\n",
      "Train Epoch: 10 [70/127 (54%)]\tLoss: 6038.534668\n",
      "Train Epoch: 10 [80/127 (62%)]\tLoss: 10904.793945\n",
      "Train Epoch: 10 [90/127 (69%)]\tLoss: 12707.502930\n",
      "Train Epoch: 10 [100/127 (77%)]\tLoss: 13868.074219\n",
      "Train Epoch: 10 [110/127 (85%)]\tLoss: 7434.870117\n",
      "Train Epoch: 10 [120/127 (92%)]\tLoss: 14789.458984\n",
      "Train Epoch: 10 [91/127 (100%)]\tLoss: 11753.973633\n",
      "Train Epoch: 11 [10/127 (8%)]\tLoss: 7553.250977\n",
      "Train Epoch: 11 [20/127 (15%)]\tLoss: 11248.228516\n",
      "Train Epoch: 11 [30/127 (23%)]\tLoss: 15272.342773\n",
      "Train Epoch: 11 [40/127 (31%)]\tLoss: 7377.866211\n",
      "Train Epoch: 11 [50/127 (38%)]\tLoss: 19070.689453\n",
      "Train Epoch: 11 [60/127 (46%)]\tLoss: 11618.427734\n",
      "Train Epoch: 11 [70/127 (54%)]\tLoss: 5716.942383\n",
      "Train Epoch: 11 [80/127 (62%)]\tLoss: 9776.888672\n",
      "Train Epoch: 11 [90/127 (69%)]\tLoss: 12200.303711\n",
      "Train Epoch: 11 [100/127 (77%)]\tLoss: 12987.173828\n",
      "Train Epoch: 11 [110/127 (85%)]\tLoss: 6911.231934\n",
      "Train Epoch: 11 [120/127 (92%)]\tLoss: 14696.221680\n",
      "Train Epoch: 11 [91/127 (100%)]\tLoss: 11230.130859\n",
      "Train Epoch: 12 [10/127 (8%)]\tLoss: 7403.662598\n",
      "Train Epoch: 12 [20/127 (15%)]\tLoss: 10363.550781\n",
      "Train Epoch: 12 [30/127 (23%)]\tLoss: 14262.931641\n",
      "Train Epoch: 12 [40/127 (31%)]\tLoss: 7136.966309\n",
      "Train Epoch: 12 [50/127 (38%)]\tLoss: 18362.837891\n",
      "Train Epoch: 12 [60/127 (46%)]\tLoss: 11103.546875\n",
      "Train Epoch: 12 [70/127 (54%)]\tLoss: 5515.333008\n",
      "Train Epoch: 12 [80/127 (62%)]\tLoss: 9301.588867\n",
      "Train Epoch: 12 [90/127 (69%)]\tLoss: 11806.328125\n",
      "Train Epoch: 12 [100/127 (77%)]\tLoss: 12317.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [110/127 (85%)]\tLoss: 6600.961914\n",
      "Train Epoch: 12 [120/127 (92%)]\tLoss: 14354.868164\n",
      "Train Epoch: 12 [91/127 (100%)]\tLoss: 10869.638672\n",
      "Train Epoch: 13 [10/127 (8%)]\tLoss: 7366.998047\n",
      "Train Epoch: 13 [20/127 (15%)]\tLoss: 9972.127930\n",
      "Train Epoch: 13 [30/127 (23%)]\tLoss: 13668.531250\n",
      "Train Epoch: 13 [40/127 (31%)]\tLoss: 7006.096191\n",
      "Train Epoch: 13 [50/127 (38%)]\tLoss: 17942.273438\n",
      "Train Epoch: 13 [60/127 (46%)]\tLoss: 10716.803711\n",
      "Train Epoch: 13 [70/127 (54%)]\tLoss: 5355.441895\n",
      "Train Epoch: 13 [80/127 (62%)]\tLoss: 9044.578125\n",
      "Train Epoch: 13 [90/127 (69%)]\tLoss: 11409.539062\n",
      "Train Epoch: 13 [100/127 (77%)]\tLoss: 11757.286133\n",
      "Train Epoch: 13 [110/127 (85%)]\tLoss: 6361.396484\n",
      "Train Epoch: 13 [120/127 (92%)]\tLoss: 13875.040039\n",
      "Train Epoch: 13 [91/127 (100%)]\tLoss: 10559.018555\n",
      "Train Epoch: 14 [10/127 (8%)]\tLoss: 7354.509277\n",
      "Train Epoch: 14 [20/127 (15%)]\tLoss: 9725.359375\n",
      "Train Epoch: 14 [30/127 (23%)]\tLoss: 13146.634766\n",
      "Train Epoch: 14 [40/127 (31%)]\tLoss: 6894.958496\n",
      "Train Epoch: 14 [50/127 (38%)]\tLoss: 17487.060547\n",
      "Train Epoch: 14 [60/127 (46%)]\tLoss: 10391.756836\n",
      "Train Epoch: 14 [70/127 (54%)]\tLoss: 5198.062500\n",
      "Train Epoch: 14 [80/127 (62%)]\tLoss: 8893.865234\n",
      "Train Epoch: 14 [90/127 (69%)]\tLoss: 11012.216797\n",
      "Train Epoch: 14 [100/127 (77%)]\tLoss: 11202.236328\n",
      "Train Epoch: 14 [110/127 (85%)]\tLoss: 6126.305176\n",
      "Train Epoch: 14 [120/127 (92%)]\tLoss: 13430.189453\n",
      "Train Epoch: 14 [91/127 (100%)]\tLoss: 10241.429688\n",
      "Train Epoch: 15 [10/127 (8%)]\tLoss: 7318.250000\n",
      "Train Epoch: 15 [20/127 (15%)]\tLoss: 9469.533203\n",
      "Train Epoch: 15 [30/127 (23%)]\tLoss: 12707.612305\n",
      "Train Epoch: 15 [40/127 (31%)]\tLoss: 6776.378418\n",
      "Train Epoch: 15 [50/127 (38%)]\tLoss: 16887.595703\n",
      "Train Epoch: 15 [60/127 (46%)]\tLoss: 10066.080078\n",
      "Train Epoch: 15 [70/127 (54%)]\tLoss: 5025.552734\n",
      "Train Epoch: 15 [80/127 (62%)]\tLoss: 8729.354492\n",
      "Train Epoch: 15 [90/127 (69%)]\tLoss: 10594.886719\n",
      "Train Epoch: 15 [100/127 (77%)]\tLoss: 10621.435547\n",
      "Train Epoch: 15 [110/127 (85%)]\tLoss: 5874.578125\n",
      "Train Epoch: 15 [120/127 (92%)]\tLoss: 13004.938477\n",
      "Train Epoch: 15 [91/127 (100%)]\tLoss: 9905.498047\n",
      "Train Epoch: 16 [10/127 (8%)]\tLoss: 7243.144043\n",
      "Train Epoch: 16 [20/127 (15%)]\tLoss: 9175.000977\n",
      "Train Epoch: 16 [30/127 (23%)]\tLoss: 12320.771484\n",
      "Train Epoch: 16 [40/127 (31%)]\tLoss: 6642.906250\n",
      "Train Epoch: 16 [50/127 (38%)]\tLoss: 16104.576172\n",
      "Train Epoch: 16 [60/127 (46%)]\tLoss: 9722.733398\n",
      "Train Epoch: 16 [70/127 (54%)]\tLoss: 4843.180176\n",
      "Train Epoch: 16 [80/127 (62%)]\tLoss: 8556.389648\n",
      "Train Epoch: 16 [90/127 (69%)]\tLoss: 10146.041992\n",
      "Train Epoch: 16 [100/127 (77%)]\tLoss: 10018.190430\n",
      "Train Epoch: 16 [110/127 (85%)]\tLoss: 5610.964355\n",
      "Train Epoch: 16 [120/127 (92%)]\tLoss: 12555.154297\n",
      "Train Epoch: 16 [91/127 (100%)]\tLoss: 9538.165039\n",
      "Train Epoch: 17 [10/127 (8%)]\tLoss: 7145.530273\n",
      "Train Epoch: 17 [20/127 (15%)]\tLoss: 8839.534180\n",
      "Train Epoch: 17 [30/127 (23%)]\tLoss: 11954.952148\n",
      "Train Epoch: 17 [40/127 (31%)]\tLoss: 6502.291992\n",
      "Train Epoch: 17 [50/127 (38%)]\tLoss: 15183.485352\n",
      "Train Epoch: 17 [60/127 (46%)]\tLoss: 9369.015625\n",
      "Train Epoch: 17 [70/127 (54%)]\tLoss: 4672.428711\n",
      "Train Epoch: 17 [80/127 (62%)]\tLoss: 8378.941406\n",
      "Train Epoch: 17 [90/127 (69%)]\tLoss: 9671.792969\n",
      "Train Epoch: 17 [100/127 (77%)]\tLoss: 9407.174805\n",
      "Train Epoch: 17 [110/127 (85%)]\tLoss: 5356.185059\n",
      "Train Epoch: 17 [120/127 (92%)]\tLoss: 12088.258789\n",
      "Train Epoch: 17 [91/127 (100%)]\tLoss: 9141.377930\n",
      "Train Epoch: 18 [10/127 (8%)]\tLoss: 7044.980469\n",
      "Train Epoch: 18 [20/127 (15%)]\tLoss: 8461.678711\n",
      "Train Epoch: 18 [30/127 (23%)]\tLoss: 11625.571289\n",
      "Train Epoch: 18 [40/127 (31%)]\tLoss: 6375.932129\n",
      "Train Epoch: 18 [50/127 (38%)]\tLoss: 14198.988281\n",
      "Train Epoch: 18 [60/127 (46%)]\tLoss: 9050.814453\n",
      "Train Epoch: 18 [70/127 (54%)]\tLoss: 4531.419922\n",
      "Train Epoch: 18 [80/127 (62%)]\tLoss: 8176.202148\n",
      "Train Epoch: 18 [90/127 (69%)]\tLoss: 9221.718750\n",
      "Train Epoch: 18 [100/127 (77%)]\tLoss: 8821.893555\n",
      "Train Epoch: 18 [110/127 (85%)]\tLoss: 5135.346680\n",
      "Train Epoch: 18 [120/127 (92%)]\tLoss: 11670.691406\n",
      "Train Epoch: 18 [91/127 (100%)]\tLoss: 8726.595703\n",
      "Train Epoch: 19 [10/127 (8%)]\tLoss: 6962.656738\n",
      "Train Epoch: 19 [20/127 (15%)]\tLoss: 8059.990234\n",
      "Train Epoch: 19 [30/127 (23%)]\tLoss: 11373.434570\n",
      "Train Epoch: 19 [40/127 (31%)]\tLoss: 6271.642578\n",
      "Train Epoch: 19 [50/127 (38%)]\tLoss: 13239.770508\n",
      "Train Epoch: 19 [60/127 (46%)]\tLoss: 8824.694336\n",
      "Train Epoch: 19 [70/127 (54%)]\tLoss: 4419.952148\n",
      "Train Epoch: 19 [80/127 (62%)]\tLoss: 7934.961426\n",
      "Train Epoch: 19 [90/127 (69%)]\tLoss: 8869.664062\n",
      "Train Epoch: 19 [100/127 (77%)]\tLoss: 8301.476562\n",
      "Train Epoch: 19 [110/127 (85%)]\tLoss: 4953.861328\n",
      "Train Epoch: 19 [120/127 (92%)]\tLoss: 11383.535156\n",
      "Train Epoch: 19 [91/127 (100%)]\tLoss: 8321.666992\n",
      "Train Epoch: 20 [10/127 (8%)]\tLoss: 6910.924805\n",
      "Train Epoch: 20 [20/127 (15%)]\tLoss: 7672.636719\n",
      "Train Epoch: 20 [30/127 (23%)]\tLoss: 11225.384766\n",
      "Train Epoch: 20 [40/127 (31%)]\tLoss: 6168.665039\n",
      "Train Epoch: 20 [50/127 (38%)]\tLoss: 12416.646484\n",
      "Train Epoch: 20 [60/127 (46%)]\tLoss: 8706.744141\n",
      "Train Epoch: 20 [70/127 (54%)]\tLoss: 4317.473145\n",
      "Train Epoch: 20 [80/127 (62%)]\tLoss: 7659.164062\n",
      "Train Epoch: 20 [90/127 (69%)]\tLoss: 8669.828125\n",
      "Train Epoch: 20 [100/127 (77%)]\tLoss: 7888.638672\n",
      "Train Epoch: 20 [110/127 (85%)]\tLoss: 4798.583008\n",
      "Train Epoch: 20 [120/127 (92%)]\tLoss: 11261.105469\n",
      "Train Epoch: 20 [91/127 (100%)]\tLoss: 7961.612305\n",
      "Train Epoch: 21 [10/127 (8%)]\tLoss: 6876.645508\n",
      "Train Epoch: 21 [20/127 (15%)]\tLoss: 7339.975586\n",
      "Train Epoch: 21 [30/127 (23%)]\tLoss: 11171.720703\n",
      "Train Epoch: 21 [40/127 (31%)]\tLoss: 6043.936523\n",
      "Train Epoch: 21 [50/127 (38%)]\tLoss: 11793.974609\n",
      "Train Epoch: 21 [60/127 (46%)]\tLoss: 8640.018555\n",
      "Train Epoch: 21 [70/127 (54%)]\tLoss: 4193.811523\n",
      "Train Epoch: 21 [80/127 (62%)]\tLoss: 7370.844727\n",
      "Train Epoch: 21 [90/127 (69%)]\tLoss: 8616.171875\n",
      "Train Epoch: 21 [100/127 (77%)]\tLoss: 7605.605469\n",
      "Train Epoch: 21 [110/127 (85%)]\tLoss: 4655.835449\n",
      "Train Epoch: 21 [120/127 (92%)]\tLoss: 11220.828125\n",
      "Train Epoch: 21 [91/127 (100%)]\tLoss: 7653.125488\n",
      "Train Epoch: 22 [10/127 (8%)]\tLoss: 6836.919434\n",
      "Train Epoch: 22 [20/127 (15%)]\tLoss: 7092.602051\n",
      "Train Epoch: 22 [30/127 (23%)]\tLoss: 11168.107422\n",
      "Train Epoch: 22 [40/127 (31%)]\tLoss: 5895.557129\n",
      "Train Epoch: 22 [50/127 (38%)]\tLoss: 11295.765625\n",
      "Train Epoch: 22 [60/127 (46%)]\tLoss: 8527.559570\n",
      "Train Epoch: 22 [70/127 (54%)]\tLoss: 4026.354248\n",
      "Train Epoch: 22 [80/127 (62%)]\tLoss: 7119.819824\n",
      "Train Epoch: 22 [90/127 (69%)]\tLoss: 8669.838867\n",
      "Train Epoch: 22 [100/127 (77%)]\tLoss: 7437.245605\n",
      "Train Epoch: 22 [110/127 (85%)]\tLoss: 4525.781250\n",
      "Train Epoch: 22 [120/127 (92%)]\tLoss: 11102.248047\n",
      "Train Epoch: 22 [91/127 (100%)]\tLoss: 7361.343750\n",
      "Train Epoch: 23 [10/127 (8%)]\tLoss: 6756.031738\n",
      "Train Epoch: 23 [20/127 (15%)]\tLoss: 6964.385742\n",
      "Train Epoch: 23 [30/127 (23%)]\tLoss: 11176.632812\n",
      "Train Epoch: 23 [40/127 (31%)]\tLoss: 5751.348633\n",
      "Train Epoch: 23 [50/127 (38%)]\tLoss: 10776.870117\n",
      "Train Epoch: 23 [60/127 (46%)]\tLoss: 8309.001953\n",
      "Train Epoch: 23 [70/127 (54%)]\tLoss: 3795.366455\n",
      "Train Epoch: 23 [80/127 (62%)]\tLoss: 6933.788574\n",
      "Train Epoch: 23 [90/127 (69%)]\tLoss: 8791.278320\n",
      "Train Epoch: 23 [100/127 (77%)]\tLoss: 7364.645508\n",
      "Train Epoch: 23 [110/127 (85%)]\tLoss: 4420.740723\n",
      "Train Epoch: 23 [120/127 (92%)]\tLoss: 10764.466797\n",
      "Train Epoch: 23 [91/127 (100%)]\tLoss: 7032.249512\n",
      "Train Epoch: 24 [10/127 (8%)]\tLoss: 6550.614746\n",
      "Train Epoch: 24 [20/127 (15%)]\tLoss: 6914.305176\n",
      "Train Epoch: 24 [30/127 (23%)]\tLoss: 11150.178711\n",
      "Train Epoch: 24 [40/127 (31%)]\tLoss: 5646.738770\n",
      "Train Epoch: 24 [50/127 (38%)]\tLoss: 10192.647461\n",
      "Train Epoch: 24 [60/127 (46%)]\tLoss: 7990.281738\n",
      "Train Epoch: 24 [70/127 (54%)]\tLoss: 3467.710938\n",
      "Train Epoch: 24 [80/127 (62%)]\tLoss: 6706.719727\n",
      "Train Epoch: 24 [90/127 (69%)]\tLoss: 8877.516602\n",
      "Train Epoch: 24 [100/127 (77%)]\tLoss: 7339.736328\n",
      "Train Epoch: 24 [110/127 (85%)]\tLoss: 4373.959961\n",
      "Train Epoch: 24 [120/127 (92%)]\tLoss: 10257.644531\n",
      "Train Epoch: 24 [91/127 (100%)]\tLoss: 6614.837402\n",
      "Train Epoch: 25 [10/127 (8%)]\tLoss: 6118.768066\n",
      "Train Epoch: 25 [20/127 (15%)]\tLoss: 6737.692383\n",
      "Train Epoch: 25 [30/127 (23%)]\tLoss: 11007.720703\n",
      "Train Epoch: 25 [40/127 (31%)]\tLoss: 5583.108398\n",
      "Train Epoch: 25 [50/127 (38%)]\tLoss: 9705.092773\n",
      "Train Epoch: 25 [60/127 (46%)]\tLoss: 7688.466797\n",
      "Train Epoch: 25 [70/127 (54%)]\tLoss: 3051.386963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [80/127 (62%)]\tLoss: 6254.717773\n",
      "Train Epoch: 25 [90/127 (69%)]\tLoss: 8730.887695\n",
      "Train Epoch: 25 [100/127 (77%)]\tLoss: 7203.932617\n",
      "Train Epoch: 25 [110/127 (85%)]\tLoss: 4456.383301\n",
      "Train Epoch: 25 [120/127 (92%)]\tLoss: 9860.920898\n",
      "Train Epoch: 25 [91/127 (100%)]\tLoss: 6080.288086\n",
      "Train Epoch: 26 [10/127 (8%)]\tLoss: 5483.820312\n",
      "Train Epoch: 26 [20/127 (15%)]\tLoss: 6263.724609\n",
      "Train Epoch: 26 [30/127 (23%)]\tLoss: 10702.868164\n",
      "Train Epoch: 26 [40/127 (31%)]\tLoss: 5500.672852\n",
      "Train Epoch: 26 [50/127 (38%)]\tLoss: 9464.204102\n",
      "Train Epoch: 26 [60/127 (46%)]\tLoss: 7557.944824\n",
      "Train Epoch: 26 [70/127 (54%)]\tLoss: 2682.848633\n",
      "Train Epoch: 26 [80/127 (62%)]\tLoss: 5701.419434\n",
      "Train Epoch: 26 [90/127 (69%)]\tLoss: 8243.265625\n",
      "Train Epoch: 26 [100/127 (77%)]\tLoss: 6753.374512\n",
      "Train Epoch: 26 [110/127 (85%)]\tLoss: 4706.873535\n",
      "Train Epoch: 26 [120/127 (92%)]\tLoss: 9670.175781\n",
      "Train Epoch: 26 [91/127 (100%)]\tLoss: 5482.759766\n",
      "Train Epoch: 27 [10/127 (8%)]\tLoss: 4891.189941\n",
      "Train Epoch: 27 [20/127 (15%)]\tLoss: 5735.133789\n",
      "Train Epoch: 27 [30/127 (23%)]\tLoss: 10324.447266\n",
      "Train Epoch: 27 [40/127 (31%)]\tLoss: 5353.665527\n",
      "Train Epoch: 27 [50/127 (38%)]\tLoss: 9424.942383\n",
      "Train Epoch: 27 [60/127 (46%)]\tLoss: 7608.433594\n",
      "Train Epoch: 27 [70/127 (54%)]\tLoss: 2552.752930\n",
      "Train Epoch: 27 [80/127 (62%)]\tLoss: 5462.935547\n",
      "Train Epoch: 27 [90/127 (69%)]\tLoss: 7603.804688\n",
      "Train Epoch: 27 [100/127 (77%)]\tLoss: 6015.518555\n",
      "Train Epoch: 27 [110/127 (85%)]\tLoss: 5091.058594\n",
      "Train Epoch: 27 [120/127 (92%)]\tLoss: 9520.078125\n",
      "Train Epoch: 27 [91/127 (100%)]\tLoss: 4986.572754\n",
      "Train Epoch: 28 [10/127 (8%)]\tLoss: 4619.602539\n",
      "Train Epoch: 28 [20/127 (15%)]\tLoss: 5531.952637\n",
      "Train Epoch: 28 [30/127 (23%)]\tLoss: 9999.148438\n",
      "Train Epoch: 28 [40/127 (31%)]\tLoss: 5190.527344\n",
      "Train Epoch: 28 [50/127 (38%)]\tLoss: 9830.107422\n",
      "Train Epoch: 28 [60/127 (46%)]\tLoss: 7740.332520\n",
      "Train Epoch: 28 [70/127 (54%)]\tLoss: 2751.747070\n",
      "Train Epoch: 28 [80/127 (62%)]\tLoss: 5544.115234\n",
      "Train Epoch: 28 [90/127 (69%)]\tLoss: 7067.392578\n",
      "Train Epoch: 28 [100/127 (77%)]\tLoss: 5252.526367\n",
      "Train Epoch: 28 [110/127 (85%)]\tLoss: 5628.196289\n",
      "Train Epoch: 28 [120/127 (92%)]\tLoss: 9694.580078\n",
      "Train Epoch: 28 [91/127 (100%)]\tLoss: 4756.289062\n",
      "Train Epoch: 29 [10/127 (8%)]\tLoss: 4766.931641\n",
      "Train Epoch: 29 [20/127 (15%)]\tLoss: 5503.285645\n",
      "Train Epoch: 29 [30/127 (23%)]\tLoss: 9736.179688\n",
      "Train Epoch: 29 [40/127 (31%)]\tLoss: 5112.353516\n",
      "Train Epoch: 29 [50/127 (38%)]\tLoss: 11424.930664\n",
      "Train Epoch: 29 [60/127 (46%)]\tLoss: 7969.828613\n",
      "Train Epoch: 29 [70/127 (54%)]\tLoss: 3329.751709\n",
      "Train Epoch: 29 [80/127 (62%)]\tLoss: 5675.705078\n",
      "Train Epoch: 29 [90/127 (69%)]\tLoss: 6705.427246\n",
      "Train Epoch: 29 [100/127 (77%)]\tLoss: 4656.380371\n",
      "Train Epoch: 29 [110/127 (85%)]\tLoss: 6269.887207\n",
      "Train Epoch: 29 [120/127 (92%)]\tLoss: 10808.109375\n",
      "Train Epoch: 29 [91/127 (100%)]\tLoss: 4956.512695\n",
      "Train Epoch: 30 [10/127 (8%)]\tLoss: 5509.494629\n",
      "Train Epoch: 30 [20/127 (15%)]\tLoss: 5436.664551\n",
      "Train Epoch: 30 [30/127 (23%)]\tLoss: 9493.582031\n",
      "Train Epoch: 30 [40/127 (31%)]\tLoss: 5188.760254\n",
      "Train Epoch: 30 [50/127 (38%)]\tLoss: 13888.247070\n",
      "Train Epoch: 30 [60/127 (46%)]\tLoss: 8616.468750\n",
      "Train Epoch: 30 [70/127 (54%)]\tLoss: 4589.434082\n",
      "Train Epoch: 30 [80/127 (62%)]\tLoss: 7434.315430\n",
      "Train Epoch: 30 [90/127 (69%)]\tLoss: 6736.672852\n",
      "Train Epoch: 30 [100/127 (77%)]\tLoss: 4410.008789\n",
      "Train Epoch: 30 [110/127 (85%)]\tLoss: 6013.308594\n",
      "Train Epoch: 30 [120/127 (92%)]\tLoss: 11474.240234\n",
      "Train Epoch: 30 [91/127 (100%)]\tLoss: 6029.250000\n",
      "Train Epoch: 31 [10/127 (8%)]\tLoss: 8226.094727\n",
      "Train Epoch: 31 [20/127 (15%)]\tLoss: 7377.776855\n",
      "Train Epoch: 31 [30/127 (23%)]\tLoss: 9539.364258\n",
      "Train Epoch: 31 [40/127 (31%)]\tLoss: 5446.845703\n",
      "Train Epoch: 31 [50/127 (38%)]\tLoss: 14350.037109\n",
      "Train Epoch: 31 [60/127 (46%)]\tLoss: 10329.577148\n",
      "Train Epoch: 31 [70/127 (54%)]\tLoss: 7228.590820\n",
      "Train Epoch: 31 [80/127 (62%)]\tLoss: 13323.650391\n",
      "Train Epoch: 31 [90/127 (69%)]\tLoss: 8597.203125\n",
      "Train Epoch: 31 [100/127 (77%)]\tLoss: 6458.145996\n",
      "Train Epoch: 31 [110/127 (85%)]\tLoss: 5438.281738\n",
      "Train Epoch: 31 [120/127 (92%)]\tLoss: 10757.478516\n",
      "Train Epoch: 31 [91/127 (100%)]\tLoss: 6275.316895\n",
      "Train Epoch: 32 [10/127 (8%)]\tLoss: 14492.454102\n",
      "Train Epoch: 32 [20/127 (15%)]\tLoss: 13184.680664\n",
      "Train Epoch: 32 [30/127 (23%)]\tLoss: 11547.832031\n",
      "Train Epoch: 32 [40/127 (31%)]\tLoss: 7261.290039\n",
      "Train Epoch: 32 [50/127 (38%)]\tLoss: 15081.053711\n",
      "Train Epoch: 32 [60/127 (46%)]\tLoss: 12006.895508\n",
      "Train Epoch: 32 [70/127 (54%)]\tLoss: 9296.545898\n",
      "Train Epoch: 32 [80/127 (62%)]\tLoss: 14941.896484\n",
      "Train Epoch: 32 [90/127 (69%)]\tLoss: 11340.827148\n",
      "Train Epoch: 32 [100/127 (77%)]\tLoss: 10954.613281\n",
      "Train Epoch: 32 [110/127 (85%)]\tLoss: 9711.129883\n",
      "Train Epoch: 32 [120/127 (92%)]\tLoss: 13323.848633\n",
      "Train Epoch: 32 [91/127 (100%)]\tLoss: 8107.459961\n",
      "Train Epoch: 33 [10/127 (8%)]\tLoss: 12746.125977\n",
      "Train Epoch: 33 [20/127 (15%)]\tLoss: 11317.701172\n",
      "Train Epoch: 33 [30/127 (23%)]\tLoss: 12277.268555\n",
      "Train Epoch: 33 [40/127 (31%)]\tLoss: 8252.761719\n",
      "Train Epoch: 33 [50/127 (38%)]\tLoss: 14500.590820\n",
      "Train Epoch: 33 [60/127 (46%)]\tLoss: 11007.879883\n",
      "Train Epoch: 33 [70/127 (54%)]\tLoss: 9373.050781\n",
      "Train Epoch: 33 [80/127 (62%)]\tLoss: 11118.634766\n",
      "Train Epoch: 33 [90/127 (69%)]\tLoss: 12525.238281\n",
      "Train Epoch: 33 [100/127 (77%)]\tLoss: 15336.387695\n",
      "Train Epoch: 33 [110/127 (85%)]\tLoss: 5873.868652\n",
      "Train Epoch: 33 [120/127 (92%)]\tLoss: 9508.371094\n",
      "Train Epoch: 33 [91/127 (100%)]\tLoss: 6346.784668\n",
      "Train Epoch: 34 [10/127 (8%)]\tLoss: 10707.184570\n",
      "Train Epoch: 34 [20/127 (15%)]\tLoss: 10357.466797\n",
      "Train Epoch: 34 [30/127 (23%)]\tLoss: 11867.091797\n",
      "Train Epoch: 34 [40/127 (31%)]\tLoss: 5199.839844\n",
      "Train Epoch: 34 [50/127 (38%)]\tLoss: 12106.075195\n",
      "Train Epoch: 34 [60/127 (46%)]\tLoss: 8722.028320\n",
      "Train Epoch: 34 [70/127 (54%)]\tLoss: 8041.749023\n",
      "Train Epoch: 34 [80/127 (62%)]\tLoss: 9545.207031\n",
      "Train Epoch: 34 [90/127 (69%)]\tLoss: 9638.996094\n",
      "Train Epoch: 34 [100/127 (77%)]\tLoss: 10343.078125\n",
      "Train Epoch: 34 [110/127 (85%)]\tLoss: 5102.805176\n",
      "Train Epoch: 34 [120/127 (92%)]\tLoss: 9845.058594\n",
      "Train Epoch: 34 [91/127 (100%)]\tLoss: 5184.077148\n",
      "Train Epoch: 35 [10/127 (8%)]\tLoss: 8563.001953\n",
      "Train Epoch: 35 [20/127 (15%)]\tLoss: 8827.875977\n",
      "Train Epoch: 35 [30/127 (23%)]\tLoss: 10339.492188\n",
      "Train Epoch: 35 [40/127 (31%)]\tLoss: 5902.193359\n",
      "Train Epoch: 35 [50/127 (38%)]\tLoss: 10660.019531\n",
      "Train Epoch: 35 [60/127 (46%)]\tLoss: 7356.424805\n",
      "Train Epoch: 35 [70/127 (54%)]\tLoss: 4591.110840\n",
      "Train Epoch: 35 [80/127 (62%)]\tLoss: 8716.756836\n",
      "Train Epoch: 35 [90/127 (69%)]\tLoss: 6948.536621\n",
      "Train Epoch: 35 [100/127 (77%)]\tLoss: 6086.320801\n",
      "Train Epoch: 35 [110/127 (85%)]\tLoss: 6161.561035\n",
      "Train Epoch: 35 [120/127 (92%)]\tLoss: 10233.301758\n",
      "Train Epoch: 35 [91/127 (100%)]\tLoss: 4687.056641\n",
      "Train Epoch: 36 [10/127 (8%)]\tLoss: 5333.759766\n",
      "Train Epoch: 36 [20/127 (15%)]\tLoss: 6779.380371\n",
      "Train Epoch: 36 [30/127 (23%)]\tLoss: 8800.297852\n",
      "Train Epoch: 36 [40/127 (31%)]\tLoss: 4812.194824\n",
      "Train Epoch: 36 [50/127 (38%)]\tLoss: 8164.039551\n",
      "Train Epoch: 36 [60/127 (46%)]\tLoss: 5905.762207\n",
      "Train Epoch: 36 [70/127 (54%)]\tLoss: 3409.530518\n",
      "Train Epoch: 36 [80/127 (62%)]\tLoss: 6862.306152\n",
      "Train Epoch: 36 [90/127 (69%)]\tLoss: 6911.027344\n",
      "Train Epoch: 36 [100/127 (77%)]\tLoss: 7301.115723\n",
      "Train Epoch: 36 [110/127 (85%)]\tLoss: 4282.287598\n",
      "Train Epoch: 36 [120/127 (92%)]\tLoss: 7795.507324\n",
      "Train Epoch: 36 [91/127 (100%)]\tLoss: 4072.974609\n",
      "Train Epoch: 37 [10/127 (8%)]\tLoss: 4799.004883\n",
      "Train Epoch: 37 [20/127 (15%)]\tLoss: 6787.293457\n",
      "Train Epoch: 37 [30/127 (23%)]\tLoss: 8356.966797\n",
      "Train Epoch: 37 [40/127 (31%)]\tLoss: 3733.339355\n",
      "Train Epoch: 37 [50/127 (38%)]\tLoss: 7780.418457\n",
      "Train Epoch: 37 [60/127 (46%)]\tLoss: 5089.083496\n",
      "Train Epoch: 37 [70/127 (54%)]\tLoss: 3211.451416\n",
      "Train Epoch: 37 [80/127 (62%)]\tLoss: 6279.869629\n",
      "Train Epoch: 37 [90/127 (69%)]\tLoss: 6465.904297\n",
      "Train Epoch: 37 [100/127 (77%)]\tLoss: 6525.464844\n",
      "Train Epoch: 37 [110/127 (85%)]\tLoss: 4466.585449\n",
      "Train Epoch: 37 [120/127 (92%)]\tLoss: 7211.420410\n",
      "Train Epoch: 37 [91/127 (100%)]\tLoss: 3100.612305\n",
      "Train Epoch: 38 [10/127 (8%)]\tLoss: 4893.626953\n",
      "Train Epoch: 38 [20/127 (15%)]\tLoss: 6332.338379\n",
      "Train Epoch: 38 [30/127 (23%)]\tLoss: 7756.335938\n",
      "Train Epoch: 38 [40/127 (31%)]\tLoss: 3839.219971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [50/127 (38%)]\tLoss: 7549.965820\n",
      "Train Epoch: 38 [60/127 (46%)]\tLoss: 4728.477539\n",
      "Train Epoch: 38 [70/127 (54%)]\tLoss: 2852.326904\n",
      "Train Epoch: 38 [80/127 (62%)]\tLoss: 6144.209961\n",
      "Train Epoch: 38 [90/127 (69%)]\tLoss: 6195.857422\n",
      "Train Epoch: 38 [100/127 (77%)]\tLoss: 5711.566406\n",
      "Train Epoch: 38 [110/127 (85%)]\tLoss: 4316.968262\n",
      "Train Epoch: 38 [120/127 (92%)]\tLoss: 6497.081055\n",
      "Train Epoch: 38 [91/127 (100%)]\tLoss: 2567.860352\n",
      "Train Epoch: 39 [10/127 (8%)]\tLoss: 4027.363770\n",
      "Train Epoch: 39 [20/127 (15%)]\tLoss: 6045.952637\n",
      "Train Epoch: 39 [30/127 (23%)]\tLoss: 7254.248047\n",
      "Train Epoch: 39 [40/127 (31%)]\tLoss: 3963.534180\n",
      "Train Epoch: 39 [50/127 (38%)]\tLoss: 6840.445801\n",
      "Train Epoch: 39 [60/127 (46%)]\tLoss: 4191.779297\n",
      "Train Epoch: 39 [70/127 (54%)]\tLoss: 2500.123779\n",
      "Train Epoch: 39 [80/127 (62%)]\tLoss: 5087.637695\n",
      "Train Epoch: 39 [90/127 (69%)]\tLoss: 5870.267090\n",
      "Train Epoch: 39 [100/127 (77%)]\tLoss: 5779.394043\n",
      "Train Epoch: 39 [110/127 (85%)]\tLoss: 4371.297852\n",
      "Train Epoch: 39 [120/127 (92%)]\tLoss: 6122.352539\n",
      "Train Epoch: 39 [91/127 (100%)]\tLoss: 2283.476562\n",
      "Train Epoch: 40 [10/127 (8%)]\tLoss: 3387.222412\n",
      "Train Epoch: 40 [20/127 (15%)]\tLoss: 5223.418945\n",
      "Train Epoch: 40 [30/127 (23%)]\tLoss: 6707.443359\n",
      "Train Epoch: 40 [40/127 (31%)]\tLoss: 3865.121826\n",
      "Train Epoch: 40 [50/127 (38%)]\tLoss: 6756.500977\n",
      "Train Epoch: 40 [60/127 (46%)]\tLoss: 4043.824463\n",
      "Train Epoch: 40 [70/127 (54%)]\tLoss: 2010.873657\n",
      "Train Epoch: 40 [80/127 (62%)]\tLoss: 4685.064941\n",
      "Train Epoch: 40 [90/127 (69%)]\tLoss: 5147.439941\n",
      "Train Epoch: 40 [100/127 (77%)]\tLoss: 4744.197754\n",
      "Train Epoch: 40 [110/127 (85%)]\tLoss: 4257.182129\n",
      "Train Epoch: 40 [120/127 (92%)]\tLoss: 5805.764648\n",
      "Train Epoch: 40 [91/127 (100%)]\tLoss: 2130.654541\n",
      "Train Epoch: 41 [10/127 (8%)]\tLoss: 3208.107910\n",
      "Train Epoch: 41 [20/127 (15%)]\tLoss: 4872.123535\n",
      "Train Epoch: 41 [30/127 (23%)]\tLoss: 6166.552246\n",
      "Train Epoch: 41 [40/127 (31%)]\tLoss: 4007.692627\n",
      "Train Epoch: 41 [50/127 (38%)]\tLoss: 6698.876953\n",
      "Train Epoch: 41 [60/127 (46%)]\tLoss: 4021.339844\n",
      "Train Epoch: 41 [70/127 (54%)]\tLoss: 1866.259766\n",
      "Train Epoch: 41 [80/127 (62%)]\tLoss: 4474.587402\n",
      "Train Epoch: 41 [90/127 (69%)]\tLoss: 4656.152344\n",
      "Train Epoch: 41 [100/127 (77%)]\tLoss: 4037.340088\n",
      "Train Epoch: 41 [110/127 (85%)]\tLoss: 4069.378418\n",
      "Train Epoch: 41 [120/127 (92%)]\tLoss: 5683.874512\n",
      "Train Epoch: 41 [91/127 (100%)]\tLoss: 2122.123779\n",
      "Train Epoch: 42 [10/127 (8%)]\tLoss: 3207.367920\n",
      "Train Epoch: 42 [20/127 (15%)]\tLoss: 4733.677246\n",
      "Train Epoch: 42 [30/127 (23%)]\tLoss: 6018.997070\n",
      "Train Epoch: 42 [40/127 (31%)]\tLoss: 3910.096436\n",
      "Train Epoch: 42 [50/127 (38%)]\tLoss: 6944.723145\n",
      "Train Epoch: 42 [60/127 (46%)]\tLoss: 4153.713379\n",
      "Train Epoch: 42 [70/127 (54%)]\tLoss: 1784.101196\n",
      "Train Epoch: 42 [80/127 (62%)]\tLoss: 4182.845703\n",
      "Train Epoch: 42 [90/127 (69%)]\tLoss: 4589.512695\n",
      "Train Epoch: 42 [100/127 (77%)]\tLoss: 4088.399658\n",
      "Train Epoch: 42 [110/127 (85%)]\tLoss: 4187.937012\n",
      "Train Epoch: 42 [120/127 (92%)]\tLoss: 5645.406738\n",
      "Train Epoch: 42 [91/127 (100%)]\tLoss: 2130.640869\n",
      "Train Epoch: 43 [10/127 (8%)]\tLoss: 3417.629883\n",
      "Train Epoch: 43 [20/127 (15%)]\tLoss: 4738.111328\n",
      "Train Epoch: 43 [30/127 (23%)]\tLoss: 5921.741211\n",
      "Train Epoch: 43 [40/127 (31%)]\tLoss: 4204.918945\n",
      "Train Epoch: 43 [50/127 (38%)]\tLoss: 7451.600586\n",
      "Train Epoch: 43 [60/127 (46%)]\tLoss: 4259.061035\n",
      "Train Epoch: 43 [70/127 (54%)]\tLoss: 1726.119751\n",
      "Train Epoch: 43 [80/127 (62%)]\tLoss: 4109.499023\n",
      "Train Epoch: 43 [90/127 (69%)]\tLoss: 4403.471680\n",
      "Train Epoch: 43 [100/127 (77%)]\tLoss: 3866.744873\n",
      "Train Epoch: 43 [110/127 (85%)]\tLoss: 4414.972656\n",
      "Train Epoch: 43 [120/127 (92%)]\tLoss: 5668.794922\n",
      "Train Epoch: 43 [91/127 (100%)]\tLoss: 2173.994385\n",
      "Train Epoch: 44 [10/127 (8%)]\tLoss: 3738.961426\n",
      "Train Epoch: 44 [20/127 (15%)]\tLoss: 4672.551758\n",
      "Train Epoch: 44 [30/127 (23%)]\tLoss: 5753.023438\n",
      "Train Epoch: 44 [40/127 (31%)]\tLoss: 4267.832520\n",
      "Train Epoch: 44 [50/127 (38%)]\tLoss: 7809.244629\n",
      "Train Epoch: 44 [60/127 (46%)]\tLoss: 4513.313477\n",
      "Train Epoch: 44 [70/127 (54%)]\tLoss: 1750.796265\n",
      "Train Epoch: 44 [80/127 (62%)]\tLoss: 4007.280518\n",
      "Train Epoch: 44 [90/127 (69%)]\tLoss: 4105.769043\n",
      "Train Epoch: 44 [100/127 (77%)]\tLoss: 3624.265137\n",
      "Train Epoch: 44 [110/127 (85%)]\tLoss: 4641.184082\n",
      "Train Epoch: 44 [120/127 (92%)]\tLoss: 5823.479980\n",
      "Train Epoch: 44 [91/127 (100%)]\tLoss: 2463.456543\n",
      "Train Epoch: 45 [10/127 (8%)]\tLoss: 4195.521484\n",
      "Train Epoch: 45 [20/127 (15%)]\tLoss: 4651.404785\n",
      "Train Epoch: 45 [30/127 (23%)]\tLoss: 5504.618164\n",
      "Train Epoch: 45 [40/127 (31%)]\tLoss: 4085.386963\n",
      "Train Epoch: 45 [50/127 (38%)]\tLoss: 7877.275879\n",
      "Train Epoch: 45 [60/127 (46%)]\tLoss: 4846.837402\n",
      "Train Epoch: 45 [70/127 (54%)]\tLoss: 1999.953735\n",
      "Train Epoch: 45 [80/127 (62%)]\tLoss: 4111.038086\n",
      "Train Epoch: 45 [90/127 (69%)]\tLoss: 3760.677002\n",
      "Train Epoch: 45 [100/127 (77%)]\tLoss: 3228.663330\n",
      "Train Epoch: 45 [110/127 (85%)]\tLoss: 4773.529297\n",
      "Train Epoch: 45 [120/127 (92%)]\tLoss: 6051.158691\n",
      "Train Epoch: 45 [91/127 (100%)]\tLoss: 2873.355225\n",
      "Train Epoch: 46 [10/127 (8%)]\tLoss: 4983.593262\n",
      "Train Epoch: 46 [20/127 (15%)]\tLoss: 4729.163086\n",
      "Train Epoch: 46 [30/127 (23%)]\tLoss: 5371.850098\n",
      "Train Epoch: 46 [40/127 (31%)]\tLoss: 3628.300049\n",
      "Train Epoch: 46 [50/127 (38%)]\tLoss: 7859.125000\n",
      "Train Epoch: 46 [60/127 (46%)]\tLoss: 5348.531738\n",
      "Train Epoch: 46 [70/127 (54%)]\tLoss: 2680.088379\n",
      "Train Epoch: 46 [80/127 (62%)]\tLoss: 4471.389160\n",
      "Train Epoch: 46 [90/127 (69%)]\tLoss: 3529.611816\n",
      "Train Epoch: 46 [100/127 (77%)]\tLoss: 2991.943359\n",
      "Train Epoch: 46 [110/127 (85%)]\tLoss: 5098.708984\n",
      "Train Epoch: 46 [120/127 (92%)]\tLoss: 6524.052734\n",
      "Train Epoch: 46 [91/127 (100%)]\tLoss: 3556.909668\n",
      "Train Epoch: 47 [10/127 (8%)]\tLoss: 6256.980469\n",
      "Train Epoch: 47 [20/127 (15%)]\tLoss: 5021.430664\n",
      "Train Epoch: 47 [30/127 (23%)]\tLoss: 5486.624023\n",
      "Train Epoch: 47 [40/127 (31%)]\tLoss: 3079.012451\n",
      "Train Epoch: 47 [50/127 (38%)]\tLoss: 7761.834473\n",
      "Train Epoch: 47 [60/127 (46%)]\tLoss: 5798.159180\n",
      "Train Epoch: 47 [70/127 (54%)]\tLoss: 3888.424072\n",
      "Train Epoch: 47 [80/127 (62%)]\tLoss: 5001.752441\n",
      "Train Epoch: 47 [90/127 (69%)]\tLoss: 3547.084229\n",
      "Train Epoch: 47 [100/127 (77%)]\tLoss: 2934.079834\n",
      "Train Epoch: 47 [110/127 (85%)]\tLoss: 5355.386230\n",
      "Train Epoch: 47 [120/127 (92%)]\tLoss: 6926.590332\n",
      "Train Epoch: 47 [91/127 (100%)]\tLoss: 4619.302246\n",
      "Train Epoch: 48 [10/127 (8%)]\tLoss: 7827.133301\n",
      "Train Epoch: 48 [20/127 (15%)]\tLoss: 5760.893555\n",
      "Train Epoch: 48 [30/127 (23%)]\tLoss: 5971.231445\n",
      "Train Epoch: 48 [40/127 (31%)]\tLoss: 2793.245605\n",
      "Train Epoch: 48 [50/127 (38%)]\tLoss: 7230.904785\n",
      "Train Epoch: 48 [60/127 (46%)]\tLoss: 5931.533691\n",
      "Train Epoch: 48 [70/127 (54%)]\tLoss: 5584.130859\n",
      "Train Epoch: 48 [80/127 (62%)]\tLoss: 6103.297852\n",
      "Train Epoch: 48 [90/127 (69%)]\tLoss: 3958.421875\n",
      "Train Epoch: 48 [100/127 (77%)]\tLoss: 3054.981689\n",
      "Train Epoch: 48 [110/127 (85%)]\tLoss: 5619.384277\n",
      "Train Epoch: 48 [120/127 (92%)]\tLoss: 7226.351074\n",
      "Train Epoch: 48 [91/127 (100%)]\tLoss: 6386.557129\n",
      "Train Epoch: 49 [10/127 (8%)]\tLoss: 9187.499023\n",
      "Train Epoch: 49 [20/127 (15%)]\tLoss: 6667.827148\n",
      "Train Epoch: 49 [30/127 (23%)]\tLoss: 6541.090332\n",
      "Train Epoch: 49 [40/127 (31%)]\tLoss: 3279.085449\n",
      "Train Epoch: 49 [50/127 (38%)]\tLoss: 6798.875000\n",
      "Train Epoch: 49 [60/127 (46%)]\tLoss: 5100.692383\n",
      "Train Epoch: 49 [70/127 (54%)]\tLoss: 6720.570312\n",
      "Train Epoch: 49 [80/127 (62%)]\tLoss: 7860.932617\n",
      "Train Epoch: 49 [90/127 (69%)]\tLoss: 4876.456055\n",
      "Train Epoch: 49 [100/127 (77%)]\tLoss: 3315.342041\n",
      "Train Epoch: 49 [110/127 (85%)]\tLoss: 5403.768555\n",
      "Train Epoch: 49 [120/127 (92%)]\tLoss: 7677.987305\n",
      "Train Epoch: 49 [91/127 (100%)]\tLoss: 8435.583008\n",
      "Train Epoch: 50 [10/127 (8%)]\tLoss: 10288.004883\n",
      "Train Epoch: 50 [20/127 (15%)]\tLoss: 8032.020020\n",
      "Train Epoch: 50 [30/127 (23%)]\tLoss: 7274.829102\n",
      "Train Epoch: 50 [40/127 (31%)]\tLoss: 4331.323730\n",
      "Train Epoch: 50 [50/127 (38%)]\tLoss: 6382.972168\n",
      "Train Epoch: 50 [60/127 (46%)]\tLoss: 4144.660645\n",
      "Train Epoch: 50 [70/127 (54%)]\tLoss: 7073.601562\n",
      "Train Epoch: 50 [80/127 (62%)]\tLoss: 10552.459961\n",
      "Train Epoch: 50 [90/127 (69%)]\tLoss: 6347.494141\n",
      "Train Epoch: 50 [100/127 (77%)]\tLoss: 4165.123535\n",
      "Train Epoch: 50 [110/127 (85%)]\tLoss: 4980.175781\n",
      "Train Epoch: 50 [120/127 (92%)]\tLoss: 8050.748047\n",
      "Train Epoch: 50 [91/127 (100%)]\tLoss: 9235.757812\n",
      "Train Epoch: 51 [10/127 (8%)]\tLoss: 12014.432617\n",
      "Train Epoch: 51 [20/127 (15%)]\tLoss: 9940.266602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [30/127 (23%)]\tLoss: 8997.510742\n",
      "Train Epoch: 51 [40/127 (31%)]\tLoss: 6716.694824\n",
      "Train Epoch: 51 [50/127 (38%)]\tLoss: 6986.237305\n",
      "Train Epoch: 51 [60/127 (46%)]\tLoss: 3263.432129\n",
      "Train Epoch: 51 [70/127 (54%)]\tLoss: 5005.606934\n",
      "Train Epoch: 51 [80/127 (62%)]\tLoss: 11728.758789\n",
      "Train Epoch: 51 [90/127 (69%)]\tLoss: 9244.975586\n",
      "Train Epoch: 51 [100/127 (77%)]\tLoss: 6743.443359\n",
      "Train Epoch: 51 [110/127 (85%)]\tLoss: 4839.214844\n",
      "Train Epoch: 51 [120/127 (92%)]\tLoss: 9039.215820\n",
      "Train Epoch: 51 [91/127 (100%)]\tLoss: 8569.252930\n",
      "Train Epoch: 52 [10/127 (8%)]\tLoss: 12709.801758\n",
      "Train Epoch: 52 [20/127 (15%)]\tLoss: 10046.600586\n",
      "Train Epoch: 52 [30/127 (23%)]\tLoss: 9265.082031\n",
      "Train Epoch: 52 [40/127 (31%)]\tLoss: 8723.458008\n",
      "Train Epoch: 52 [50/127 (38%)]\tLoss: 8781.131836\n",
      "Train Epoch: 52 [60/127 (46%)]\tLoss: 4876.080078\n",
      "Train Epoch: 52 [70/127 (54%)]\tLoss: 4118.539062\n",
      "Train Epoch: 52 [80/127 (62%)]\tLoss: 9200.944336\n",
      "Train Epoch: 52 [90/127 (69%)]\tLoss: 8481.872070\n",
      "Train Epoch: 52 [100/127 (77%)]\tLoss: 7543.104004\n",
      "Train Epoch: 52 [110/127 (85%)]\tLoss: 3896.876709\n",
      "Train Epoch: 52 [120/127 (92%)]\tLoss: 7105.000977\n",
      "Train Epoch: 52 [91/127 (100%)]\tLoss: 10745.686523\n",
      "Train Epoch: 53 [10/127 (8%)]\tLoss: 10574.786133\n",
      "Train Epoch: 53 [20/127 (15%)]\tLoss: 8785.780273\n",
      "Train Epoch: 53 [30/127 (23%)]\tLoss: 7797.398926\n",
      "Train Epoch: 53 [40/127 (31%)]\tLoss: 7279.864258\n",
      "Train Epoch: 53 [50/127 (38%)]\tLoss: 10354.247070\n",
      "Train Epoch: 53 [60/127 (46%)]\tLoss: 4503.937012\n",
      "Train Epoch: 53 [70/127 (54%)]\tLoss: 3660.680664\n",
      "Train Epoch: 53 [80/127 (62%)]\tLoss: 6635.929199\n",
      "Train Epoch: 53 [90/127 (69%)]\tLoss: 7899.207031\n",
      "Train Epoch: 53 [100/127 (77%)]\tLoss: 7943.399414\n",
      "Train Epoch: 53 [110/127 (85%)]\tLoss: 4419.446289\n",
      "Train Epoch: 53 [120/127 (92%)]\tLoss: 8221.100586\n",
      "Train Epoch: 53 [91/127 (100%)]\tLoss: 10507.143555\n",
      "Train Epoch: 54 [10/127 (8%)]\tLoss: 9443.119141\n",
      "Train Epoch: 54 [20/127 (15%)]\tLoss: 7399.203125\n",
      "Train Epoch: 54 [30/127 (23%)]\tLoss: 8706.500000\n",
      "Train Epoch: 54 [40/127 (31%)]\tLoss: 4908.860352\n",
      "Train Epoch: 54 [50/127 (38%)]\tLoss: 9664.390625\n",
      "Train Epoch: 54 [60/127 (46%)]\tLoss: 4218.404297\n",
      "Train Epoch: 54 [70/127 (54%)]\tLoss: 2888.969727\n",
      "Train Epoch: 54 [80/127 (62%)]\tLoss: 6069.534180\n",
      "Train Epoch: 54 [90/127 (69%)]\tLoss: 6931.701172\n",
      "Train Epoch: 54 [100/127 (77%)]\tLoss: 8958.448242\n",
      "Train Epoch: 54 [110/127 (85%)]\tLoss: 4467.189453\n",
      "Train Epoch: 54 [120/127 (92%)]\tLoss: 6818.338867\n",
      "Train Epoch: 54 [91/127 (100%)]\tLoss: 5857.916016\n",
      "Train Epoch: 55 [10/127 (8%)]\tLoss: 4665.763184\n",
      "Train Epoch: 55 [20/127 (15%)]\tLoss: 7291.146484\n",
      "Train Epoch: 55 [30/127 (23%)]\tLoss: 7479.667480\n",
      "Train Epoch: 55 [40/127 (31%)]\tLoss: 4168.427734\n",
      "Train Epoch: 55 [50/127 (38%)]\tLoss: 8775.845703\n",
      "Train Epoch: 55 [60/127 (46%)]\tLoss: 4849.505859\n",
      "Train Epoch: 55 [70/127 (54%)]\tLoss: 2462.463135\n",
      "Train Epoch: 55 [80/127 (62%)]\tLoss: 5649.108398\n",
      "Train Epoch: 55 [90/127 (69%)]\tLoss: 5553.929688\n",
      "Train Epoch: 55 [100/127 (77%)]\tLoss: 6621.190430\n",
      "Train Epoch: 55 [110/127 (85%)]\tLoss: 4728.822754\n",
      "Train Epoch: 55 [120/127 (92%)]\tLoss: 7189.394043\n",
      "Train Epoch: 55 [91/127 (100%)]\tLoss: 3933.777344\n",
      "Train Epoch: 56 [10/127 (8%)]\tLoss: 4193.872070\n",
      "Train Epoch: 56 [20/127 (15%)]\tLoss: 5209.190430\n",
      "Train Epoch: 56 [30/127 (23%)]\tLoss: 5762.599609\n",
      "Train Epoch: 56 [40/127 (31%)]\tLoss: 4015.343262\n",
      "Train Epoch: 56 [50/127 (38%)]\tLoss: 8052.379395\n",
      "Train Epoch: 56 [60/127 (46%)]\tLoss: 4246.285645\n",
      "Train Epoch: 56 [70/127 (54%)]\tLoss: 2220.765625\n",
      "Train Epoch: 56 [80/127 (62%)]\tLoss: 5082.765625\n",
      "Train Epoch: 56 [90/127 (69%)]\tLoss: 4396.793945\n",
      "Train Epoch: 56 [100/127 (77%)]\tLoss: 4674.194336\n",
      "Train Epoch: 56 [110/127 (85%)]\tLoss: 3587.629883\n",
      "Train Epoch: 56 [120/127 (92%)]\tLoss: 5683.700684\n",
      "Train Epoch: 56 [91/127 (100%)]\tLoss: 3938.859375\n",
      "Train Epoch: 57 [10/127 (8%)]\tLoss: 3662.713135\n",
      "Train Epoch: 57 [20/127 (15%)]\tLoss: 5706.945801\n",
      "Train Epoch: 57 [30/127 (23%)]\tLoss: 6988.020020\n",
      "Train Epoch: 57 [40/127 (31%)]\tLoss: 3565.344727\n",
      "Train Epoch: 57 [50/127 (38%)]\tLoss: 7857.823730\n",
      "Train Epoch: 57 [60/127 (46%)]\tLoss: 3956.218262\n",
      "Train Epoch: 57 [70/127 (54%)]\tLoss: 2532.489502\n",
      "Train Epoch: 57 [80/127 (62%)]\tLoss: 5096.467285\n",
      "Train Epoch: 57 [90/127 (69%)]\tLoss: 4480.704590\n",
      "Train Epoch: 57 [100/127 (77%)]\tLoss: 4600.871094\n",
      "Train Epoch: 57 [110/127 (85%)]\tLoss: 4097.222168\n",
      "Train Epoch: 57 [120/127 (92%)]\tLoss: 5518.423828\n",
      "Train Epoch: 57 [91/127 (100%)]\tLoss: 2643.377686\n",
      "Train Epoch: 58 [10/127 (8%)]\tLoss: 4355.019043\n",
      "Train Epoch: 58 [20/127 (15%)]\tLoss: 5672.775879\n",
      "Train Epoch: 58 [30/127 (23%)]\tLoss: 6453.313965\n",
      "Train Epoch: 58 [40/127 (31%)]\tLoss: 3873.297363\n",
      "Train Epoch: 58 [50/127 (38%)]\tLoss: 6747.758789\n",
      "Train Epoch: 58 [60/127 (46%)]\tLoss: 3584.865479\n",
      "Train Epoch: 58 [70/127 (54%)]\tLoss: 2737.776855\n",
      "Train Epoch: 58 [80/127 (62%)]\tLoss: 6478.123535\n",
      "Train Epoch: 58 [90/127 (69%)]\tLoss: 3738.142090\n",
      "Train Epoch: 58 [100/127 (77%)]\tLoss: 4001.687744\n",
      "Train Epoch: 58 [110/127 (85%)]\tLoss: 4113.951172\n",
      "Train Epoch: 58 [120/127 (92%)]\tLoss: 5391.058105\n",
      "Train Epoch: 58 [91/127 (100%)]\tLoss: 2506.099365\n",
      "Train Epoch: 59 [10/127 (8%)]\tLoss: 4373.358398\n",
      "Train Epoch: 59 [20/127 (15%)]\tLoss: 5340.858887\n",
      "Train Epoch: 59 [30/127 (23%)]\tLoss: 5492.103516\n",
      "Train Epoch: 59 [40/127 (31%)]\tLoss: 3725.635742\n",
      "Train Epoch: 59 [50/127 (38%)]\tLoss: 7127.026367\n",
      "Train Epoch: 59 [60/127 (46%)]\tLoss: 3468.636963\n",
      "Train Epoch: 59 [70/127 (54%)]\tLoss: 2665.014404\n",
      "Train Epoch: 59 [80/127 (62%)]\tLoss: 7095.260254\n",
      "Train Epoch: 59 [90/127 (69%)]\tLoss: 3554.187256\n",
      "Train Epoch: 59 [100/127 (77%)]\tLoss: 3550.970703\n",
      "Train Epoch: 59 [110/127 (85%)]\tLoss: 3484.777588\n",
      "Train Epoch: 59 [120/127 (92%)]\tLoss: 5529.828125\n",
      "Train Epoch: 59 [91/127 (100%)]\tLoss: 2196.565186\n",
      "Train Epoch: 60 [10/127 (8%)]\tLoss: 5999.185059\n",
      "Train Epoch: 60 [20/127 (15%)]\tLoss: 5338.537109\n",
      "Train Epoch: 60 [30/127 (23%)]\tLoss: 5450.388184\n",
      "Train Epoch: 60 [40/127 (31%)]\tLoss: 3804.414795\n",
      "Train Epoch: 60 [50/127 (38%)]\tLoss: 8865.904297\n",
      "Train Epoch: 60 [60/127 (46%)]\tLoss: 3763.897949\n",
      "Train Epoch: 60 [70/127 (54%)]\tLoss: 3142.790527\n",
      "Train Epoch: 60 [80/127 (62%)]\tLoss: 6621.333984\n",
      "Train Epoch: 60 [90/127 (69%)]\tLoss: 3943.569092\n",
      "Train Epoch: 60 [100/127 (77%)]\tLoss: 4415.053711\n",
      "Train Epoch: 60 [110/127 (85%)]\tLoss: 4497.793457\n",
      "Train Epoch: 60 [120/127 (92%)]\tLoss: 6482.209473\n",
      "Train Epoch: 60 [91/127 (100%)]\tLoss: 2249.711182\n",
      "Train Epoch: 61 [10/127 (8%)]\tLoss: 4702.467285\n",
      "Train Epoch: 61 [20/127 (15%)]\tLoss: 6004.076660\n",
      "Train Epoch: 61 [30/127 (23%)]\tLoss: 5770.405273\n",
      "Train Epoch: 61 [40/127 (31%)]\tLoss: 4489.955566\n",
      "Train Epoch: 61 [50/127 (38%)]\tLoss: 10861.633789\n",
      "Train Epoch: 61 [60/127 (46%)]\tLoss: 3741.724609\n",
      "Train Epoch: 61 [70/127 (54%)]\tLoss: 3126.927979\n",
      "Train Epoch: 61 [80/127 (62%)]\tLoss: 4766.509277\n",
      "Train Epoch: 61 [90/127 (69%)]\tLoss: 3782.340576\n",
      "Train Epoch: 61 [100/127 (77%)]\tLoss: 4426.669434\n",
      "Train Epoch: 61 [110/127 (85%)]\tLoss: 5032.702637\n",
      "Train Epoch: 61 [120/127 (92%)]\tLoss: 8229.121094\n",
      "Train Epoch: 61 [91/127 (100%)]\tLoss: 5175.671387\n",
      "Train Epoch: 62 [10/127 (8%)]\tLoss: 3564.089355\n",
      "Train Epoch: 62 [20/127 (15%)]\tLoss: 4839.164062\n",
      "Train Epoch: 62 [30/127 (23%)]\tLoss: 5617.328613\n",
      "Train Epoch: 62 [40/127 (31%)]\tLoss: 4697.628906\n",
      "Train Epoch: 62 [50/127 (38%)]\tLoss: 14560.051758\n",
      "Train Epoch: 62 [60/127 (46%)]\tLoss: 3742.383301\n",
      "Train Epoch: 62 [70/127 (54%)]\tLoss: 2957.294678\n",
      "Train Epoch: 62 [80/127 (62%)]\tLoss: 7276.503418\n",
      "Train Epoch: 62 [90/127 (69%)]\tLoss: 3729.937744\n",
      "Train Epoch: 62 [100/127 (77%)]\tLoss: 4327.241211\n",
      "Train Epoch: 62 [110/127 (85%)]\tLoss: 4038.612305\n",
      "Train Epoch: 62 [120/127 (92%)]\tLoss: 7035.528320\n",
      "Train Epoch: 62 [91/127 (100%)]\tLoss: 2614.829834\n",
      "Train Epoch: 63 [10/127 (8%)]\tLoss: 5731.374023\n",
      "Train Epoch: 63 [20/127 (15%)]\tLoss: 14489.747070\n",
      "Train Epoch: 63 [30/127 (23%)]\tLoss: 6164.124512\n",
      "Train Epoch: 63 [40/127 (31%)]\tLoss: 5122.006836\n",
      "Train Epoch: 63 [50/127 (38%)]\tLoss: 12066.173828\n",
      "Train Epoch: 63 [60/127 (46%)]\tLoss: 4749.082520\n",
      "Train Epoch: 63 [70/127 (54%)]\tLoss: 4382.285645\n",
      "Train Epoch: 63 [80/127 (62%)]\tLoss: 17224.148438\n",
      "Train Epoch: 63 [90/127 (69%)]\tLoss: 5260.508789\n",
      "Train Epoch: 63 [100/127 (77%)]\tLoss: 6563.196777\n",
      "Train Epoch: 63 [110/127 (85%)]\tLoss: 4254.050781\n",
      "Train Epoch: 63 [120/127 (92%)]\tLoss: 12599.098633\n",
      "Train Epoch: 63 [91/127 (100%)]\tLoss: 2829.032227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64 [10/127 (8%)]\tLoss: 9001.969727\n",
      "Train Epoch: 64 [20/127 (15%)]\tLoss: 10379.287109\n",
      "Train Epoch: 64 [30/127 (23%)]\tLoss: 6688.828613\n",
      "Train Epoch: 64 [40/127 (31%)]\tLoss: 8633.866211\n",
      "Train Epoch: 64 [50/127 (38%)]\tLoss: 16047.791016\n",
      "Train Epoch: 64 [60/127 (46%)]\tLoss: 9460.733398\n",
      "Train Epoch: 64 [70/127 (54%)]\tLoss: 6124.352539\n",
      "Train Epoch: 64 [80/127 (62%)]\tLoss: 7174.817383\n",
      "Train Epoch: 64 [90/127 (69%)]\tLoss: 5358.419922\n",
      "Train Epoch: 64 [100/127 (77%)]\tLoss: 5665.178711\n",
      "Train Epoch: 64 [110/127 (85%)]\tLoss: 3802.990723\n",
      "Train Epoch: 64 [120/127 (92%)]\tLoss: 6729.059082\n",
      "Train Epoch: 64 [91/127 (100%)]\tLoss: 4867.863281\n",
      "Train Epoch: 65 [10/127 (8%)]\tLoss: 8398.829102\n",
      "Train Epoch: 65 [20/127 (15%)]\tLoss: 6563.293457\n",
      "Train Epoch: 65 [30/127 (23%)]\tLoss: 11523.066406\n",
      "Train Epoch: 65 [40/127 (31%)]\tLoss: 4830.090332\n",
      "Train Epoch: 65 [50/127 (38%)]\tLoss: 9330.286133\n",
      "Train Epoch: 65 [60/127 (46%)]\tLoss: 6736.979492\n",
      "Train Epoch: 65 [70/127 (54%)]\tLoss: 5009.837891\n",
      "Train Epoch: 65 [80/127 (62%)]\tLoss: 7497.958008\n",
      "Train Epoch: 65 [90/127 (69%)]\tLoss: 6908.167969\n",
      "Train Epoch: 65 [100/127 (77%)]\tLoss: 5979.341797\n",
      "Train Epoch: 65 [110/127 (85%)]\tLoss: 5527.710449\n",
      "Train Epoch: 65 [120/127 (92%)]\tLoss: 8294.724609\n",
      "Train Epoch: 65 [91/127 (100%)]\tLoss: 5066.040527\n",
      "Train Epoch: 66 [10/127 (8%)]\tLoss: 10734.064453\n",
      "Train Epoch: 66 [20/127 (15%)]\tLoss: 6896.062500\n",
      "Train Epoch: 66 [30/127 (23%)]\tLoss: 6509.131348\n",
      "Train Epoch: 66 [40/127 (31%)]\tLoss: 6554.005859\n",
      "Train Epoch: 66 [50/127 (38%)]\tLoss: 11296.664062\n",
      "Train Epoch: 66 [60/127 (46%)]\tLoss: 4879.157227\n",
      "Train Epoch: 66 [70/127 (54%)]\tLoss: 4463.954102\n",
      "Train Epoch: 66 [80/127 (62%)]\tLoss: 8439.781250\n",
      "Train Epoch: 66 [90/127 (69%)]\tLoss: 6138.574219\n",
      "Train Epoch: 66 [100/127 (77%)]\tLoss: 9019.565430\n",
      "Train Epoch: 66 [110/127 (85%)]\tLoss: 6693.219727\n",
      "Train Epoch: 66 [120/127 (92%)]\tLoss: 7958.288574\n",
      "Train Epoch: 66 [91/127 (100%)]\tLoss: 7261.387695\n",
      "Train Epoch: 67 [10/127 (8%)]\tLoss: 10378.877930\n",
      "Train Epoch: 67 [20/127 (15%)]\tLoss: 8368.963867\n",
      "Train Epoch: 67 [30/127 (23%)]\tLoss: 7734.125000\n",
      "Train Epoch: 67 [40/127 (31%)]\tLoss: 4321.834473\n",
      "Train Epoch: 67 [50/127 (38%)]\tLoss: 10023.518555\n",
      "Train Epoch: 67 [60/127 (46%)]\tLoss: 5123.111328\n",
      "Train Epoch: 67 [70/127 (54%)]\tLoss: 4945.645508\n",
      "Train Epoch: 67 [80/127 (62%)]\tLoss: 8229.315430\n",
      "Train Epoch: 67 [90/127 (69%)]\tLoss: 7257.924805\n",
      "Train Epoch: 67 [100/127 (77%)]\tLoss: 9198.886719\n",
      "Train Epoch: 67 [110/127 (85%)]\tLoss: 7050.876953\n",
      "Train Epoch: 67 [120/127 (92%)]\tLoss: 9572.739258\n",
      "Train Epoch: 67 [91/127 (100%)]\tLoss: 6888.697754\n",
      "Train Epoch: 68 [10/127 (8%)]\tLoss: 4979.642578\n",
      "Train Epoch: 68 [20/127 (15%)]\tLoss: 6770.192871\n",
      "Train Epoch: 68 [30/127 (23%)]\tLoss: 9280.132812\n",
      "Train Epoch: 68 [40/127 (31%)]\tLoss: 8073.696777\n",
      "Train Epoch: 68 [50/127 (38%)]\tLoss: 7710.359375\n",
      "Train Epoch: 68 [60/127 (46%)]\tLoss: 4830.904785\n",
      "Train Epoch: 68 [70/127 (54%)]\tLoss: 4562.056641\n",
      "Train Epoch: 68 [80/127 (62%)]\tLoss: 9078.662109\n",
      "Train Epoch: 68 [90/127 (69%)]\tLoss: 8327.531250\n",
      "Train Epoch: 68 [100/127 (77%)]\tLoss: 10290.671875\n",
      "Train Epoch: 68 [110/127 (85%)]\tLoss: 7793.978027\n",
      "Train Epoch: 68 [120/127 (92%)]\tLoss: 9208.207031\n",
      "Train Epoch: 68 [91/127 (100%)]\tLoss: 10430.276367\n",
      "Train Epoch: 69 [10/127 (8%)]\tLoss: 4903.473633\n",
      "Train Epoch: 69 [20/127 (15%)]\tLoss: 7742.044922\n",
      "Train Epoch: 69 [30/127 (23%)]\tLoss: 8271.094727\n",
      "Train Epoch: 69 [40/127 (31%)]\tLoss: 5351.547363\n",
      "Train Epoch: 69 [50/127 (38%)]\tLoss: 12263.407227\n",
      "Train Epoch: 69 [60/127 (46%)]\tLoss: 6643.193848\n",
      "Train Epoch: 69 [70/127 (54%)]\tLoss: 4854.591309\n",
      "Train Epoch: 69 [80/127 (62%)]\tLoss: 8283.447266\n",
      "Train Epoch: 69 [90/127 (69%)]\tLoss: 6840.913574\n",
      "Train Epoch: 69 [100/127 (77%)]\tLoss: 8879.845703\n",
      "Train Epoch: 69 [110/127 (85%)]\tLoss: 4477.948730\n",
      "Train Epoch: 69 [120/127 (92%)]\tLoss: 8691.235352\n",
      "Train Epoch: 69 [91/127 (100%)]\tLoss: 4000.253906\n",
      "Train Epoch: 70 [10/127 (8%)]\tLoss: 10967.663086\n",
      "Train Epoch: 70 [20/127 (15%)]\tLoss: 9777.007812\n",
      "Train Epoch: 70 [30/127 (23%)]\tLoss: 9024.525391\n",
      "Train Epoch: 70 [40/127 (31%)]\tLoss: 4204.083496\n",
      "Train Epoch: 70 [50/127 (38%)]\tLoss: 8826.644531\n",
      "Train Epoch: 70 [60/127 (46%)]\tLoss: 6278.744141\n",
      "Train Epoch: 70 [70/127 (54%)]\tLoss: 8045.732422\n",
      "Train Epoch: 70 [80/127 (62%)]\tLoss: 11799.003906\n",
      "Train Epoch: 70 [90/127 (69%)]\tLoss: 9209.706055\n",
      "Train Epoch: 70 [100/127 (77%)]\tLoss: 10005.037109\n",
      "Train Epoch: 70 [110/127 (85%)]\tLoss: 8377.016602\n",
      "Train Epoch: 70 [120/127 (92%)]\tLoss: 10934.271484\n",
      "Train Epoch: 70 [91/127 (100%)]\tLoss: 15259.606445\n",
      "Train Epoch: 71 [10/127 (8%)]\tLoss: 3326.134033\n",
      "Train Epoch: 71 [20/127 (15%)]\tLoss: 15531.391602\n",
      "Train Epoch: 71 [30/127 (23%)]\tLoss: 12521.923828\n",
      "Train Epoch: 71 [40/127 (31%)]\tLoss: 4850.888672\n",
      "Train Epoch: 71 [50/127 (38%)]\tLoss: 11344.326172\n",
      "Train Epoch: 71 [60/127 (46%)]\tLoss: 6645.766113\n",
      "Train Epoch: 71 [70/127 (54%)]\tLoss: 3468.215820\n",
      "Train Epoch: 71 [80/127 (62%)]\tLoss: 20138.218750\n",
      "Train Epoch: 71 [90/127 (69%)]\tLoss: 4837.736816\n",
      "Train Epoch: 71 [100/127 (77%)]\tLoss: 7672.159180\n",
      "Train Epoch: 71 [110/127 (85%)]\tLoss: 5806.399902\n",
      "Train Epoch: 71 [120/127 (92%)]\tLoss: 8212.096680\n",
      "Train Epoch: 71 [91/127 (100%)]\tLoss: 10912.674805\n",
      "Train Epoch: 72 [10/127 (8%)]\tLoss: 6339.884766\n",
      "Train Epoch: 72 [20/127 (15%)]\tLoss: 17277.234375\n",
      "Train Epoch: 72 [30/127 (23%)]\tLoss: 16268.951172\n",
      "Train Epoch: 72 [40/127 (31%)]\tLoss: 3442.464600\n",
      "Train Epoch: 72 [50/127 (38%)]\tLoss: 21016.548828\n",
      "Train Epoch: 72 [60/127 (46%)]\tLoss: 8421.768555\n",
      "Train Epoch: 72 [70/127 (54%)]\tLoss: 7758.048340\n",
      "Train Epoch: 72 [80/127 (62%)]\tLoss: 9036.497070\n",
      "Train Epoch: 72 [90/127 (69%)]\tLoss: 7564.027832\n",
      "Train Epoch: 72 [100/127 (77%)]\tLoss: 8491.143555\n",
      "Train Epoch: 72 [110/127 (85%)]\tLoss: 5935.409668\n",
      "Train Epoch: 72 [120/127 (92%)]\tLoss: 14790.704102\n",
      "Train Epoch: 72 [91/127 (100%)]\tLoss: 4498.547363\n",
      "Train Epoch: 73 [10/127 (8%)]\tLoss: 4852.416992\n",
      "Train Epoch: 73 [20/127 (15%)]\tLoss: 7646.484863\n",
      "Train Epoch: 73 [30/127 (23%)]\tLoss: 9453.714844\n",
      "Train Epoch: 73 [40/127 (31%)]\tLoss: 6302.405762\n",
      "Train Epoch: 73 [50/127 (38%)]\tLoss: 13149.769531\n",
      "Train Epoch: 73 [60/127 (46%)]\tLoss: 6063.495605\n",
      "Train Epoch: 73 [70/127 (54%)]\tLoss: 7082.544434\n",
      "Train Epoch: 73 [80/127 (62%)]\tLoss: 9745.318359\n",
      "Train Epoch: 73 [90/127 (69%)]\tLoss: 10474.785156\n",
      "Train Epoch: 73 [100/127 (77%)]\tLoss: 11880.462891\n",
      "Train Epoch: 73 [110/127 (85%)]\tLoss: 6794.847656\n",
      "Train Epoch: 73 [120/127 (92%)]\tLoss: 7212.926270\n",
      "Train Epoch: 73 [91/127 (100%)]\tLoss: 6889.168945\n",
      "Train Epoch: 74 [10/127 (8%)]\tLoss: 6235.558594\n",
      "Train Epoch: 74 [20/127 (15%)]\tLoss: 11040.557617\n",
      "Train Epoch: 74 [30/127 (23%)]\tLoss: 8723.836914\n",
      "Train Epoch: 74 [40/127 (31%)]\tLoss: 10559.125977\n",
      "Train Epoch: 74 [50/127 (38%)]\tLoss: 9983.865234\n",
      "Train Epoch: 74 [60/127 (46%)]\tLoss: 5522.659180\n",
      "Train Epoch: 74 [70/127 (54%)]\tLoss: 3990.629150\n",
      "Train Epoch: 74 [80/127 (62%)]\tLoss: 8912.443359\n",
      "Train Epoch: 74 [90/127 (69%)]\tLoss: 4954.932617\n",
      "Train Epoch: 74 [100/127 (77%)]\tLoss: 4762.209473\n",
      "Train Epoch: 74 [110/127 (85%)]\tLoss: 6528.047852\n",
      "Train Epoch: 74 [120/127 (92%)]\tLoss: 10421.337891\n",
      "Train Epoch: 74 [91/127 (100%)]\tLoss: 6100.229004\n",
      "Train Epoch: 75 [10/127 (8%)]\tLoss: 4817.256836\n",
      "Train Epoch: 75 [20/127 (15%)]\tLoss: 8740.428711\n",
      "Train Epoch: 75 [30/127 (23%)]\tLoss: 7332.415039\n",
      "Train Epoch: 75 [40/127 (31%)]\tLoss: 8110.003906\n",
      "Train Epoch: 75 [50/127 (38%)]\tLoss: 9588.455078\n",
      "Train Epoch: 75 [60/127 (46%)]\tLoss: 4231.041504\n",
      "Train Epoch: 75 [70/127 (54%)]\tLoss: 2817.337646\n",
      "Train Epoch: 75 [80/127 (62%)]\tLoss: 7915.386230\n",
      "Train Epoch: 75 [90/127 (69%)]\tLoss: 6240.753418\n",
      "Train Epoch: 75 [100/127 (77%)]\tLoss: 7827.953125\n",
      "Train Epoch: 75 [110/127 (85%)]\tLoss: 7462.144043\n",
      "Train Epoch: 75 [120/127 (92%)]\tLoss: 10959.392578\n",
      "Train Epoch: 75 [91/127 (100%)]\tLoss: 4078.931396\n",
      "Train Epoch: 76 [10/127 (8%)]\tLoss: 5126.304199\n",
      "Train Epoch: 76 [20/127 (15%)]\tLoss: 6430.215332\n",
      "Train Epoch: 76 [30/127 (23%)]\tLoss: 6113.146973\n",
      "Train Epoch: 76 [40/127 (31%)]\tLoss: 4501.291992\n",
      "Train Epoch: 76 [50/127 (38%)]\tLoss: 17626.556641\n",
      "Train Epoch: 76 [60/127 (46%)]\tLoss: 6957.767578\n",
      "Train Epoch: 76 [70/127 (54%)]\tLoss: 3357.748047\n",
      "Train Epoch: 76 [80/127 (62%)]\tLoss: 8659.741211\n",
      "Train Epoch: 76 [90/127 (69%)]\tLoss: 4893.162598\n",
      "Train Epoch: 76 [100/127 (77%)]\tLoss: 6431.104004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 76 [110/127 (85%)]\tLoss: 7900.870117\n",
      "Train Epoch: 76 [120/127 (92%)]\tLoss: 9982.335938\n",
      "Train Epoch: 76 [91/127 (100%)]\tLoss: 3730.280762\n",
      "Train Epoch: 77 [10/127 (8%)]\tLoss: 5076.791016\n",
      "Train Epoch: 77 [20/127 (15%)]\tLoss: 13558.093750\n",
      "Train Epoch: 77 [30/127 (23%)]\tLoss: 7299.111328\n",
      "Train Epoch: 77 [40/127 (31%)]\tLoss: 4622.819336\n",
      "Train Epoch: 77 [50/127 (38%)]\tLoss: 7976.703125\n",
      "Train Epoch: 77 [60/127 (46%)]\tLoss: 3389.622314\n",
      "Train Epoch: 77 [70/127 (54%)]\tLoss: 1920.732056\n",
      "Train Epoch: 77 [80/127 (62%)]\tLoss: 10502.270508\n",
      "Train Epoch: 77 [90/127 (69%)]\tLoss: 6223.332520\n",
      "Train Epoch: 77 [100/127 (77%)]\tLoss: 7994.521973\n",
      "Train Epoch: 77 [110/127 (85%)]\tLoss: 4466.436523\n",
      "Train Epoch: 77 [120/127 (92%)]\tLoss: 8611.812500\n",
      "Train Epoch: 77 [91/127 (100%)]\tLoss: 3384.630371\n",
      "Train Epoch: 78 [10/127 (8%)]\tLoss: 8006.552246\n",
      "Train Epoch: 78 [20/127 (15%)]\tLoss: 8785.662109\n",
      "Train Epoch: 78 [30/127 (23%)]\tLoss: 6785.547363\n",
      "Train Epoch: 78 [40/127 (31%)]\tLoss: 4472.541504\n",
      "Train Epoch: 78 [50/127 (38%)]\tLoss: 10884.676758\n",
      "Train Epoch: 78 [60/127 (46%)]\tLoss: 5411.972168\n",
      "Train Epoch: 78 [70/127 (54%)]\tLoss: 3026.000488\n",
      "Train Epoch: 78 [80/127 (62%)]\tLoss: 6208.207031\n",
      "Train Epoch: 78 [90/127 (69%)]\tLoss: 4144.141113\n",
      "Train Epoch: 78 [100/127 (77%)]\tLoss: 5641.247070\n",
      "Train Epoch: 78 [110/127 (85%)]\tLoss: 4182.080566\n",
      "Train Epoch: 78 [120/127 (92%)]\tLoss: 5954.473633\n",
      "Train Epoch: 78 [91/127 (100%)]\tLoss: 4011.798828\n",
      "Train Epoch: 79 [10/127 (8%)]\tLoss: 3970.167480\n",
      "Train Epoch: 79 [20/127 (15%)]\tLoss: 7783.258789\n",
      "Train Epoch: 79 [30/127 (23%)]\tLoss: 5558.592773\n",
      "Train Epoch: 79 [40/127 (31%)]\tLoss: 3285.664795\n",
      "Train Epoch: 79 [50/127 (38%)]\tLoss: 7442.448730\n",
      "Train Epoch: 79 [60/127 (46%)]\tLoss: 3305.687256\n",
      "Train Epoch: 79 [70/127 (54%)]\tLoss: 1963.699951\n",
      "Train Epoch: 79 [80/127 (62%)]\tLoss: 5647.268555\n",
      "Train Epoch: 79 [90/127 (69%)]\tLoss: 4083.501709\n",
      "Train Epoch: 79 [100/127 (77%)]\tLoss: 3561.479248\n",
      "Train Epoch: 79 [110/127 (85%)]\tLoss: 3340.055176\n",
      "Train Epoch: 79 [120/127 (92%)]\tLoss: 5524.775879\n",
      "Train Epoch: 79 [91/127 (100%)]\tLoss: 3910.203369\n",
      "Train Epoch: 80 [10/127 (8%)]\tLoss: 4779.536621\n",
      "Train Epoch: 80 [20/127 (15%)]\tLoss: 6250.589844\n",
      "Train Epoch: 80 [30/127 (23%)]\tLoss: 4822.008789\n",
      "Train Epoch: 80 [40/127 (31%)]\tLoss: 3455.030762\n",
      "Train Epoch: 80 [50/127 (38%)]\tLoss: 6836.584961\n",
      "Train Epoch: 80 [60/127 (46%)]\tLoss: 2773.918701\n",
      "Train Epoch: 80 [70/127 (54%)]\tLoss: 2116.403320\n",
      "Train Epoch: 80 [80/127 (62%)]\tLoss: 4938.554688\n",
      "Train Epoch: 80 [90/127 (69%)]\tLoss: 3991.741943\n",
      "Train Epoch: 80 [100/127 (77%)]\tLoss: 5069.867676\n",
      "Train Epoch: 80 [110/127 (85%)]\tLoss: 3442.412109\n",
      "Train Epoch: 80 [120/127 (92%)]\tLoss: 5591.270020\n",
      "Train Epoch: 80 [91/127 (100%)]\tLoss: 2135.830566\n",
      "Train Epoch: 81 [10/127 (8%)]\tLoss: 3718.146729\n",
      "Train Epoch: 81 [20/127 (15%)]\tLoss: 5121.791016\n",
      "Train Epoch: 81 [30/127 (23%)]\tLoss: 5329.810059\n",
      "Train Epoch: 81 [40/127 (31%)]\tLoss: 4638.443848\n",
      "Train Epoch: 81 [50/127 (38%)]\tLoss: 8814.478516\n",
      "Train Epoch: 81 [60/127 (46%)]\tLoss: 3229.997803\n",
      "Train Epoch: 81 [70/127 (54%)]\tLoss: 1899.902466\n",
      "Train Epoch: 81 [80/127 (62%)]\tLoss: 3799.374268\n",
      "Train Epoch: 81 [90/127 (69%)]\tLoss: 3550.944824\n",
      "Train Epoch: 81 [100/127 (77%)]\tLoss: 4006.334717\n",
      "Train Epoch: 81 [110/127 (85%)]\tLoss: 3708.717773\n",
      "Train Epoch: 81 [120/127 (92%)]\tLoss: 6828.535645\n",
      "Train Epoch: 81 [91/127 (100%)]\tLoss: 6224.322266\n",
      "Train Epoch: 82 [10/127 (8%)]\tLoss: 3423.758789\n",
      "Train Epoch: 82 [20/127 (15%)]\tLoss: 4503.959473\n",
      "Train Epoch: 82 [30/127 (23%)]\tLoss: 3707.559326\n",
      "Train Epoch: 82 [40/127 (31%)]\tLoss: 3069.948975\n",
      "Train Epoch: 82 [50/127 (38%)]\tLoss: 8322.381836\n",
      "Train Epoch: 82 [60/127 (46%)]\tLoss: 2590.842529\n",
      "Train Epoch: 82 [70/127 (54%)]\tLoss: 2107.255127\n",
      "Train Epoch: 82 [80/127 (62%)]\tLoss: 4939.911621\n",
      "Train Epoch: 82 [90/127 (69%)]\tLoss: 4084.138428\n",
      "Train Epoch: 82 [100/127 (77%)]\tLoss: 4341.119141\n",
      "Train Epoch: 82 [110/127 (85%)]\tLoss: 2605.096191\n",
      "Train Epoch: 82 [120/127 (92%)]\tLoss: 6456.480469\n",
      "Train Epoch: 82 [91/127 (100%)]\tLoss: 7080.770508\n",
      "Train Epoch: 83 [10/127 (8%)]\tLoss: 2635.531250\n",
      "Train Epoch: 83 [20/127 (15%)]\tLoss: 7384.441895\n",
      "Train Epoch: 83 [30/127 (23%)]\tLoss: 3780.461182\n",
      "Train Epoch: 83 [40/127 (31%)]\tLoss: 2729.776367\n",
      "Train Epoch: 83 [50/127 (38%)]\tLoss: 6888.582031\n",
      "Train Epoch: 83 [60/127 (46%)]\tLoss: 2426.954346\n",
      "Train Epoch: 83 [70/127 (54%)]\tLoss: 1640.764648\n",
      "Train Epoch: 83 [80/127 (62%)]\tLoss: 10554.920898\n",
      "Train Epoch: 83 [90/127 (69%)]\tLoss: 3638.287109\n",
      "Train Epoch: 83 [100/127 (77%)]\tLoss: 4185.496094\n",
      "Train Epoch: 83 [110/127 (85%)]\tLoss: 2721.613037\n",
      "Train Epoch: 83 [120/127 (92%)]\tLoss: 4589.178223\n",
      "Train Epoch: 83 [91/127 (100%)]\tLoss: 3333.568115\n",
      "Train Epoch: 84 [10/127 (8%)]\tLoss: 3052.921875\n",
      "Train Epoch: 84 [20/127 (15%)]\tLoss: 12239.445312\n",
      "Train Epoch: 84 [30/127 (23%)]\tLoss: 4028.928711\n",
      "Train Epoch: 84 [40/127 (31%)]\tLoss: 3011.955078\n",
      "Train Epoch: 84 [50/127 (38%)]\tLoss: 6296.337402\n",
      "Train Epoch: 84 [60/127 (46%)]\tLoss: 2505.558350\n",
      "Train Epoch: 84 [70/127 (54%)]\tLoss: 1630.139526\n",
      "Train Epoch: 84 [80/127 (62%)]\tLoss: 10496.831055\n",
      "Train Epoch: 84 [90/127 (69%)]\tLoss: 3455.611084\n",
      "Train Epoch: 84 [100/127 (77%)]\tLoss: 4333.966309\n",
      "Train Epoch: 84 [110/127 (85%)]\tLoss: 3712.554443\n",
      "Train Epoch: 84 [120/127 (92%)]\tLoss: 7999.459473\n",
      "Train Epoch: 84 [91/127 (100%)]\tLoss: 4005.531982\n",
      "Train Epoch: 85 [10/127 (8%)]\tLoss: 3563.486328\n",
      "Train Epoch: 85 [20/127 (15%)]\tLoss: 5483.854492\n",
      "Train Epoch: 85 [30/127 (23%)]\tLoss: 4283.172363\n",
      "Train Epoch: 85 [40/127 (31%)]\tLoss: 3747.165527\n",
      "Train Epoch: 85 [50/127 (38%)]\tLoss: 14528.171875\n",
      "Train Epoch: 85 [60/127 (46%)]\tLoss: 2706.301270\n",
      "Train Epoch: 85 [70/127 (54%)]\tLoss: 1425.401367\n",
      "Train Epoch: 85 [80/127 (62%)]\tLoss: 3790.480469\n",
      "Train Epoch: 85 [90/127 (69%)]\tLoss: 4639.398926\n",
      "Train Epoch: 85 [100/127 (77%)]\tLoss: 4743.405273\n",
      "Train Epoch: 85 [110/127 (85%)]\tLoss: 4657.328125\n",
      "Train Epoch: 85 [120/127 (92%)]\tLoss: 11116.928711\n",
      "Train Epoch: 85 [91/127 (100%)]\tLoss: 4662.774902\n",
      "Train Epoch: 86 [10/127 (8%)]\tLoss: 4955.698242\n",
      "Train Epoch: 86 [20/127 (15%)]\tLoss: 6776.457520\n",
      "Train Epoch: 86 [30/127 (23%)]\tLoss: 4277.494141\n",
      "Train Epoch: 86 [40/127 (31%)]\tLoss: 5200.056152\n",
      "Train Epoch: 86 [50/127 (38%)]\tLoss: 9080.765625\n",
      "Train Epoch: 86 [60/127 (46%)]\tLoss: 3009.447510\n",
      "Train Epoch: 86 [70/127 (54%)]\tLoss: 2097.127930\n",
      "Train Epoch: 86 [80/127 (62%)]\tLoss: 6901.210938\n",
      "Train Epoch: 86 [90/127 (69%)]\tLoss: 3515.279053\n",
      "Train Epoch: 86 [100/127 (77%)]\tLoss: 3933.836426\n",
      "Train Epoch: 86 [110/127 (85%)]\tLoss: 4360.462891\n",
      "Train Epoch: 86 [120/127 (92%)]\tLoss: 5083.061523\n",
      "Train Epoch: 86 [91/127 (100%)]\tLoss: 3949.131104\n",
      "Train Epoch: 87 [10/127 (8%)]\tLoss: 3347.222656\n",
      "Train Epoch: 87 [20/127 (15%)]\tLoss: 4967.832031\n",
      "Train Epoch: 87 [30/127 (23%)]\tLoss: 5546.747070\n",
      "Train Epoch: 87 [40/127 (31%)]\tLoss: 3282.854248\n",
      "Train Epoch: 87 [50/127 (38%)]\tLoss: 6173.452148\n",
      "Train Epoch: 87 [60/127 (46%)]\tLoss: 2807.434082\n",
      "Train Epoch: 87 [70/127 (54%)]\tLoss: 1567.813965\n",
      "Train Epoch: 87 [80/127 (62%)]\tLoss: 3816.044922\n",
      "Train Epoch: 87 [90/127 (69%)]\tLoss: 3558.573975\n",
      "Train Epoch: 87 [100/127 (77%)]\tLoss: 4912.894043\n",
      "Train Epoch: 87 [110/127 (85%)]\tLoss: 3257.849365\n",
      "Train Epoch: 87 [120/127 (92%)]\tLoss: 4403.338867\n",
      "Train Epoch: 87 [91/127 (100%)]\tLoss: 3109.879639\n",
      "Train Epoch: 88 [10/127 (8%)]\tLoss: 3054.007812\n",
      "Train Epoch: 88 [20/127 (15%)]\tLoss: 4298.825195\n",
      "Train Epoch: 88 [30/127 (23%)]\tLoss: 3871.723633\n",
      "Train Epoch: 88 [40/127 (31%)]\tLoss: 4252.961426\n",
      "Train Epoch: 88 [50/127 (38%)]\tLoss: 6116.037598\n",
      "Train Epoch: 88 [60/127 (46%)]\tLoss: 2823.942627\n",
      "Train Epoch: 88 [70/127 (54%)]\tLoss: 1943.332397\n",
      "Train Epoch: 88 [80/127 (62%)]\tLoss: 3623.474121\n",
      "Train Epoch: 88 [90/127 (69%)]\tLoss: 3397.868408\n",
      "Train Epoch: 88 [100/127 (77%)]\tLoss: 5029.200195\n",
      "Train Epoch: 88 [110/127 (85%)]\tLoss: 4063.583740\n",
      "Train Epoch: 88 [120/127 (92%)]\tLoss: 4813.864746\n",
      "Train Epoch: 88 [91/127 (100%)]\tLoss: 3056.166260\n",
      "Train Epoch: 89 [10/127 (8%)]\tLoss: 2897.836426\n",
      "Train Epoch: 89 [20/127 (15%)]\tLoss: 3217.433594\n",
      "Train Epoch: 89 [30/127 (23%)]\tLoss: 3986.100098\n",
      "Train Epoch: 89 [40/127 (31%)]\tLoss: 4617.601074\n",
      "Train Epoch: 89 [50/127 (38%)]\tLoss: 7240.373535\n",
      "Train Epoch: 89 [60/127 (46%)]\tLoss: 3362.041016\n",
      "Train Epoch: 89 [70/127 (54%)]\tLoss: 2868.524658\n",
      "Train Epoch: 89 [80/127 (62%)]\tLoss: 4170.814941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89 [90/127 (69%)]\tLoss: 3202.533203\n",
      "Train Epoch: 89 [100/127 (77%)]\tLoss: 4909.957031\n",
      "Train Epoch: 89 [110/127 (85%)]\tLoss: 3934.675293\n",
      "Train Epoch: 89 [120/127 (92%)]\tLoss: 3809.381836\n",
      "Train Epoch: 89 [91/127 (100%)]\tLoss: 2350.421631\n",
      "Train Epoch: 90 [10/127 (8%)]\tLoss: 3605.983887\n",
      "Train Epoch: 90 [20/127 (15%)]\tLoss: 3410.208008\n",
      "Train Epoch: 90 [30/127 (23%)]\tLoss: 4177.762207\n",
      "Train Epoch: 90 [40/127 (31%)]\tLoss: 4030.790283\n",
      "Train Epoch: 90 [50/127 (38%)]\tLoss: 6340.895508\n",
      "Train Epoch: 90 [60/127 (46%)]\tLoss: 3641.039062\n",
      "Train Epoch: 90 [70/127 (54%)]\tLoss: 2775.219727\n",
      "Train Epoch: 90 [80/127 (62%)]\tLoss: 4038.131592\n",
      "Train Epoch: 90 [90/127 (69%)]\tLoss: 2836.807617\n",
      "Train Epoch: 90 [100/127 (77%)]\tLoss: 3632.864990\n",
      "Train Epoch: 90 [110/127 (85%)]\tLoss: 3047.021729\n",
      "Train Epoch: 90 [120/127 (92%)]\tLoss: 2655.961914\n",
      "Train Epoch: 90 [91/127 (100%)]\tLoss: 3689.646973\n",
      "Train Epoch: 91 [10/127 (8%)]\tLoss: 3382.260498\n",
      "Train Epoch: 91 [20/127 (15%)]\tLoss: 3472.479980\n",
      "Train Epoch: 91 [30/127 (23%)]\tLoss: 3925.636230\n",
      "Train Epoch: 91 [40/127 (31%)]\tLoss: 3678.096680\n",
      "Train Epoch: 91 [50/127 (38%)]\tLoss: 5362.433105\n",
      "Train Epoch: 91 [60/127 (46%)]\tLoss: 2558.510498\n",
      "Train Epoch: 91 [70/127 (54%)]\tLoss: 1644.821655\n",
      "Train Epoch: 91 [80/127 (62%)]\tLoss: 3261.951904\n",
      "Train Epoch: 91 [90/127 (69%)]\tLoss: 3489.725586\n",
      "Train Epoch: 91 [100/127 (77%)]\tLoss: 5144.759277\n",
      "Train Epoch: 91 [110/127 (85%)]\tLoss: 5357.754883\n",
      "Train Epoch: 91 [120/127 (92%)]\tLoss: 3472.716064\n",
      "Train Epoch: 91 [91/127 (100%)]\tLoss: 2048.931396\n",
      "Train Epoch: 92 [10/127 (8%)]\tLoss: 2295.052246\n",
      "Train Epoch: 92 [20/127 (15%)]\tLoss: 2551.939941\n",
      "Train Epoch: 92 [30/127 (23%)]\tLoss: 3516.929443\n",
      "Train Epoch: 92 [40/127 (31%)]\tLoss: 4265.166504\n",
      "Train Epoch: 92 [50/127 (38%)]\tLoss: 7601.996582\n",
      "Train Epoch: 92 [60/127 (46%)]\tLoss: 3454.433594\n",
      "Train Epoch: 92 [70/127 (54%)]\tLoss: 2216.218262\n",
      "Train Epoch: 92 [80/127 (62%)]\tLoss: 3402.657227\n",
      "Train Epoch: 92 [90/127 (69%)]\tLoss: 3026.979980\n",
      "Train Epoch: 92 [100/127 (77%)]\tLoss: 4184.097656\n",
      "Train Epoch: 92 [110/127 (85%)]\tLoss: 4180.289551\n",
      "Train Epoch: 92 [120/127 (92%)]\tLoss: 3092.743164\n",
      "Train Epoch: 92 [91/127 (100%)]\tLoss: 3269.279541\n",
      "Train Epoch: 93 [10/127 (8%)]\tLoss: 3283.106934\n",
      "Train Epoch: 93 [20/127 (15%)]\tLoss: 2970.514160\n",
      "Train Epoch: 93 [30/127 (23%)]\tLoss: 3161.747559\n",
      "Train Epoch: 93 [40/127 (31%)]\tLoss: 3436.908447\n",
      "Train Epoch: 93 [50/127 (38%)]\tLoss: 6361.570312\n",
      "Train Epoch: 93 [60/127 (46%)]\tLoss: 2907.394287\n",
      "Train Epoch: 93 [70/127 (54%)]\tLoss: 2138.209473\n",
      "Train Epoch: 93 [80/127 (62%)]\tLoss: 3619.532959\n",
      "Train Epoch: 93 [90/127 (69%)]\tLoss: 3439.553955\n",
      "Train Epoch: 93 [100/127 (77%)]\tLoss: 4711.997070\n",
      "Train Epoch: 93 [110/127 (85%)]\tLoss: 3038.737793\n",
      "Train Epoch: 93 [120/127 (92%)]\tLoss: 3828.784668\n",
      "Train Epoch: 93 [91/127 (100%)]\tLoss: 2751.259766\n",
      "Train Epoch: 94 [10/127 (8%)]\tLoss: 2412.512451\n",
      "Train Epoch: 94 [20/127 (15%)]\tLoss: 3718.070068\n",
      "Train Epoch: 94 [30/127 (23%)]\tLoss: 3534.287598\n",
      "Train Epoch: 94 [40/127 (31%)]\tLoss: 2670.904541\n",
      "Train Epoch: 94 [50/127 (38%)]\tLoss: 5313.631836\n",
      "Train Epoch: 94 [60/127 (46%)]\tLoss: 2656.280029\n",
      "Train Epoch: 94 [70/127 (54%)]\tLoss: 1702.733643\n",
      "Train Epoch: 94 [80/127 (62%)]\tLoss: 3713.441650\n",
      "Train Epoch: 94 [90/127 (69%)]\tLoss: 3715.247559\n",
      "Train Epoch: 94 [100/127 (77%)]\tLoss: 5838.928711\n",
      "Train Epoch: 94 [110/127 (85%)]\tLoss: 3322.858643\n",
      "Train Epoch: 94 [120/127 (92%)]\tLoss: 4492.417969\n",
      "Train Epoch: 94 [91/127 (100%)]\tLoss: 3283.931885\n",
      "Train Epoch: 95 [10/127 (8%)]\tLoss: 2628.849365\n",
      "Train Epoch: 95 [20/127 (15%)]\tLoss: 9330.125977\n",
      "Train Epoch: 95 [30/127 (23%)]\tLoss: 3721.999756\n",
      "Train Epoch: 95 [40/127 (31%)]\tLoss: 8620.565430\n",
      "Train Epoch: 95 [50/127 (38%)]\tLoss: 24816.375000\n",
      "Train Epoch: 95 [60/127 (46%)]\tLoss: 3585.929443\n",
      "Train Epoch: 95 [70/127 (54%)]\tLoss: 7412.361328\n",
      "Train Epoch: 95 [80/127 (62%)]\tLoss: 13629.250977\n",
      "Train Epoch: 95 [90/127 (69%)]\tLoss: 8680.589844\n",
      "Train Epoch: 95 [100/127 (77%)]\tLoss: 14562.271484\n",
      "Train Epoch: 95 [110/127 (85%)]\tLoss: 10740.386719\n",
      "Train Epoch: 95 [120/127 (92%)]\tLoss: 25725.031250\n",
      "Train Epoch: 95 [91/127 (100%)]\tLoss: 6252.905762\n",
      "Train Epoch: 96 [10/127 (8%)]\tLoss: 5152.763672\n",
      "Train Epoch: 96 [20/127 (15%)]\tLoss: 15974.849609\n",
      "Train Epoch: 96 [30/127 (23%)]\tLoss: 5614.890137\n",
      "Train Epoch: 96 [40/127 (31%)]\tLoss: 5231.404785\n",
      "Train Epoch: 96 [50/127 (38%)]\tLoss: 12912.410156\n",
      "Train Epoch: 96 [60/127 (46%)]\tLoss: 5829.735352\n",
      "Train Epoch: 96 [70/127 (54%)]\tLoss: 4421.007324\n",
      "Train Epoch: 96 [80/127 (62%)]\tLoss: 6049.280762\n",
      "Train Epoch: 96 [90/127 (69%)]\tLoss: 4994.138672\n",
      "Train Epoch: 96 [100/127 (77%)]\tLoss: 6159.405273\n",
      "Train Epoch: 96 [110/127 (85%)]\tLoss: 4867.306152\n",
      "Train Epoch: 96 [120/127 (92%)]\tLoss: 7486.110840\n",
      "Train Epoch: 96 [91/127 (100%)]\tLoss: 3418.583740\n",
      "Train Epoch: 97 [10/127 (8%)]\tLoss: 4643.815918\n",
      "Train Epoch: 97 [20/127 (15%)]\tLoss: 6374.115723\n",
      "Train Epoch: 97 [30/127 (23%)]\tLoss: 4305.243164\n",
      "Train Epoch: 97 [40/127 (31%)]\tLoss: 5326.718262\n",
      "Train Epoch: 97 [50/127 (38%)]\tLoss: 8387.206055\n",
      "Train Epoch: 97 [60/127 (46%)]\tLoss: 3592.805176\n",
      "Train Epoch: 97 [70/127 (54%)]\tLoss: 2547.150146\n",
      "Train Epoch: 97 [80/127 (62%)]\tLoss: 7896.476074\n",
      "Train Epoch: 97 [90/127 (69%)]\tLoss: 3437.079834\n",
      "Train Epoch: 97 [100/127 (77%)]\tLoss: 3698.752441\n",
      "Train Epoch: 97 [110/127 (85%)]\tLoss: 3080.581299\n",
      "Train Epoch: 97 [120/127 (92%)]\tLoss: 6388.356445\n",
      "Train Epoch: 97 [91/127 (100%)]\tLoss: 2538.479980\n",
      "Train Epoch: 98 [10/127 (8%)]\tLoss: 4084.402588\n",
      "Train Epoch: 98 [20/127 (15%)]\tLoss: 9406.872070\n",
      "Train Epoch: 98 [30/127 (23%)]\tLoss: 4597.096680\n",
      "Train Epoch: 98 [40/127 (31%)]\tLoss: 2919.676270\n",
      "Train Epoch: 98 [50/127 (38%)]\tLoss: 7102.522949\n",
      "Train Epoch: 98 [60/127 (46%)]\tLoss: 2840.822021\n",
      "Train Epoch: 98 [70/127 (54%)]\tLoss: 2315.811523\n",
      "Train Epoch: 98 [80/127 (62%)]\tLoss: 7420.545898\n",
      "Train Epoch: 98 [90/127 (69%)]\tLoss: 3829.614502\n",
      "Train Epoch: 98 [100/127 (77%)]\tLoss: 4136.388184\n",
      "Train Epoch: 98 [110/127 (85%)]\tLoss: 3117.198975\n",
      "Train Epoch: 98 [120/127 (92%)]\tLoss: 6305.837402\n",
      "Train Epoch: 98 [91/127 (100%)]\tLoss: 3100.661133\n",
      "Train Epoch: 99 [10/127 (8%)]\tLoss: 3221.484619\n",
      "Train Epoch: 99 [20/127 (15%)]\tLoss: 5833.527832\n",
      "Train Epoch: 99 [30/127 (23%)]\tLoss: 5356.356934\n",
      "Train Epoch: 99 [40/127 (31%)]\tLoss: 4949.516113\n",
      "Train Epoch: 99 [50/127 (38%)]\tLoss: 7977.500977\n",
      "Train Epoch: 99 [60/127 (46%)]\tLoss: 2785.190918\n",
      "Train Epoch: 99 [70/127 (54%)]\tLoss: 1665.953003\n",
      "Train Epoch: 99 [80/127 (62%)]\tLoss: 4681.641113\n",
      "Train Epoch: 99 [90/127 (69%)]\tLoss: 4643.563477\n",
      "Train Epoch: 99 [100/127 (77%)]\tLoss: 6233.057617\n",
      "Train Epoch: 99 [110/127 (85%)]\tLoss: 5202.149414\n",
      "Train Epoch: 99 [120/127 (92%)]\tLoss: 7484.499512\n",
      "Train Epoch: 99 [91/127 (100%)]\tLoss: 2958.652832\n"
     ]
    }
   ],
   "source": [
    "train_model(model, loss_fn,data_loader=train_loader,epochs=100,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data0 = torch.from_numpy(a[0])\n",
    "test_data0 = test_data0.type('torch.FloatTensor')\n",
    "test_data0 = test_data0.to(device)\n",
    "encoded_data0 = model.module.encoder(test_data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = torch.from_numpy(a[1])\n",
    "test_data1 = test_data1.type('torch.FloatTensor')\n",
    "test_data1 = test_data1.to(device)\n",
    "encoded_data1 = model.module.encoder(test_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data3 = torch.from_numpy(a[0]+a[1])\n",
    "test_data3 = test_data3.type('torch.FloatTensor')\n",
    "test_data3 = test_data3.to(device)\n",
    "encoded_data3 = model.module.encoder(test_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.3477e-03, -2.8503e-02, -3.5980e-02, -4.2717e-02, -1.0071e-03,\n",
       "         2.7954e-02, -3.7109e-02, -5.6534e-03, -1.9974e-02, -3.1555e-02,\n",
       "         4.3396e-02,  4.6177e-02, -2.6779e-02,  7.5684e-03, -1.4038e-02,\n",
       "        -7.6294e-04, -2.4780e-02,  1.8066e-02, -2.4246e-02, -4.3335e-03,\n",
       "         2.0473e-02, -2.2644e-02,  4.2419e-03, -2.8778e-02, -1.4475e-02,\n",
       "        -2.7100e-02, -5.7068e-03, -3.1738e-03, -8.2397e-04, -5.6152e-03,\n",
       "        -1.7845e-02, -8.6060e-03,  2.5696e-02,  8.9188e-03, -1.7813e-02,\n",
       "         2.3499e-02, -1.3672e-02, -3.2166e-02, -4.0161e-02, -5.9814e-03,\n",
       "        -2.6245e-03, -7.0229e-03, -2.8076e-03, -2.7618e-02,  2.6947e-02,\n",
       "        -8.1177e-03,  3.2013e-02, -9.7046e-03,  4.6326e-02, -5.8594e-03,\n",
       "         2.5757e-02,  1.1658e-02,  6.9275e-03, -1.8311e-04, -3.2883e-02,\n",
       "         2.5513e-02,  5.8136e-03,  7.9346e-04,  7.9117e-03,  1.6907e-02,\n",
       "         1.4038e-02,  8.3618e-03,  4.3945e-03,  3.4790e-03,  9.2163e-03,\n",
       "        -2.9816e-02, -6.3477e-02,  2.5513e-02, -6.4392e-03, -1.3947e-02,\n",
       "        -1.2045e-02,  7.6294e-05,  3.8696e-02,  7.4463e-03,  2.0264e-02,\n",
       "        -1.8250e-02,  6.7940e-03,  4.5166e-03,  1.4160e-02, -1.7975e-02,\n",
       "         1.4563e-02, -8.9722e-03, -2.7222e-02,  1.5900e-02, -3.1982e-02,\n",
       "         5.7373e-03,  1.1524e-02,  1.1597e-02, -4.2725e-04,  2.5192e-02,\n",
       "         4.3121e-02, -5.8899e-03, -9.3842e-03, -1.7899e-02,  1.5381e-02,\n",
       "         2.4170e-02, -8.6060e-03, -1.2234e-02,  1.5442e-02, -4.7028e-02,\n",
       "         2.3682e-02,  2.3438e-02, -3.1799e-02,  2.4963e-02, -6.4026e-02,\n",
       "        -3.3264e-03, -2.2522e-02,  2.2614e-02, -3.8574e-02,  1.1780e-02,\n",
       "        -1.1047e-02, -2.7342e-03, -2.8839e-02,  2.9297e-03,  1.4374e-02,\n",
       "         1.8036e-02,  4.2542e-02,  8.8196e-03, -1.7807e-02,  3.4943e-03,\n",
       "         4.6692e-03,  1.5869e-02, -1.1871e-02,  8.9722e-03, -3.7781e-02,\n",
       "        -4.4861e-03, -1.1658e-02, -3.7842e-03, -4.0894e-03, -7.4951e-02,\n",
       "         9.9487e-03,  3.1891e-03, -5.0781e-02, -2.1973e-03,  1.3031e-02,\n",
       "        -1.4229e-02, -3.2593e-02,  3.4119e-02,  9.0027e-03,  5.5218e-03,\n",
       "         2.6810e-02,  3.1784e-02, -1.0986e-02, -5.0171e-02, -1.5259e-02,\n",
       "        -4.3922e-02,  6.2866e-03,  2.2430e-03,  3.0396e-02,  3.5950e-02,\n",
       "        -1.4992e-02,  1.4259e-02, -2.8900e-02,  1.0254e-02,  2.8168e-02,\n",
       "         6.2294e-03,  3.6621e-03,  2.7466e-03,  4.9316e-02,  3.8498e-02,\n",
       "         2.4561e-02, -4.1565e-02,  2.4292e-02,  3.6926e-02, -3.3737e-02,\n",
       "         4.1687e-02, -2.2217e-02, -2.2095e-02,  2.7527e-02, -6.4087e-04,\n",
       "         2.1812e-02,  2.8503e-02,  5.8594e-03,  4.1504e-02, -1.0986e-03,\n",
       "        -1.1444e-02,  1.4191e-02, -4.9774e-02,  1.9619e-02,  1.5930e-02,\n",
       "        -3.9734e-02, -9.4528e-03, -1.4503e-02,  2.2278e-03,  2.4048e-02,\n",
       "        -3.4531e-02,  2.0790e-02, -3.1738e-02, -1.5503e-02, -1.3855e-02,\n",
       "        -1.9756e-02,  8.3923e-03, -3.1799e-02, -2.6123e-02,  4.3030e-03,\n",
       "        -2.5024e-02,  3.4180e-03, -8.7433e-03, -3.8757e-03, -2.3834e-02,\n",
       "         7.6904e-03,  3.1555e-02, -2.3499e-02,  5.2490e-03, -1.3519e-02,\n",
       "        -1.3733e-02,  8.2855e-03, -2.3804e-02,  3.0701e-02,  1.7334e-02,\n",
       "        -6.5674e-02, -9.5749e-03,  1.9064e-02, -1.0284e-02,  2.4231e-02,\n",
       "        -1.1230e-02, -3.0589e-02, -2.8931e-02,  7.8125e-03,  2.0557e-02,\n",
       "        -1.6342e-02, -1.0559e-02, -4.2297e-02, -1.2115e-02, -1.3855e-02,\n",
       "        -1.9485e-02, -1.6083e-02,  1.1719e-02, -1.6693e-02, -4.2267e-02,\n",
       "        -3.0029e-02,  9.0027e-04, -7.5684e-03,  3.4912e-02, -3.2623e-02,\n",
       "         1.0681e-02, -3.1361e-02,  1.2711e-02,  3.1265e-02, -9.6436e-03,\n",
       "         2.4902e-02, -1.9501e-02,  2.1484e-02,  5.4016e-02,  5.1727e-03,\n",
       "        -1.8860e-02, -1.7021e-02, -1.0986e-02, -2.5145e-02, -3.3691e-02,\n",
       "         3.3112e-02,  1.7700e-03, -1.1017e-02,  6.5613e-03, -1.7373e-02,\n",
       "         3.9062e-03, -5.2429e-02, -8.8730e-03,  1.5289e-02,  1.5991e-02,\n",
       "         2.2331e-02, -6.4697e-03, -3.4119e-02,  1.3977e-02, -3.6011e-02,\n",
       "        -1.2215e-02,  3.3676e-02, -1.2634e-02,  1.2726e-02,  1.7586e-02,\n",
       "        -7.1411e-03, -3.4180e-02, -2.9907e-02,  2.3209e-02, -1.1436e-02,\n",
       "         1.9226e-03, -1.4236e-02, -1.3977e-02,  1.9403e-04,  2.2705e-02,\n",
       "        -6.7749e-03,  2.8214e-02, -2.1179e-02, -5.7373e-03,  9.4910e-03,\n",
       "        -2.1301e-02,  1.8005e-02, -2.1729e-02,  3.6346e-02, -1.8311e-03,\n",
       "         2.8564e-02,  9.6550e-03,  1.8097e-02, -2.5833e-02,  3.1616e-02,\n",
       "         3.5522e-02,  2.2827e-02,  1.0193e-02,  1.4572e-02,  7.2784e-03,\n",
       "        -3.4058e-02, -4.0400e-02, -1.8799e-02, -6.6528e-03,  2.0386e-02,\n",
       "        -1.0391e-02,  2.8320e-02, -5.7739e-02, -1.6846e-02, -6.1722e-03,\n",
       "        -2.3926e-02, -1.5587e-02,  2.1576e-02,  2.2842e-02, -1.0071e-03,\n",
       "         7.3242e-04,  3.8818e-02,  9.4604e-03, -1.8341e-02,  2.5925e-02,\n",
       "         3.0380e-02, -5.9929e-03, -1.7822e-02, -2.1271e-02,  4.7607e-03,\n",
       "         1.9409e-02,  6.1035e-05,  8.6060e-03, -6.7139e-04,  2.6550e-03,\n",
       "        -3.4119e-02, -1.9379e-02,  6.7291e-03, -8.1940e-03,  2.1057e-02,\n",
       "        -1.4229e-02,  2.3193e-03,  2.9972e-02,  7.1411e-03,  6.4697e-03,\n",
       "         2.5330e-02, -4.2648e-03, -4.0222e-02, -1.9104e-02,  2.2125e-02,\n",
       "        -4.3457e-02, -8.9111e-03, -1.7426e-02,  4.6692e-02, -1.0132e-02,\n",
       "         1.2451e-02, -7.6904e-03, -1.0559e-02,  2.2888e-03, -3.0945e-02,\n",
       "        -3.3813e-02, -3.5217e-02,  1.0437e-02,  1.8311e-04, -1.3000e-02,\n",
       "         5.2551e-02,  4.6539e-03, -1.4343e-02, -4.1504e-02, -3.6865e-02,\n",
       "        -1.4648e-02,  3.3081e-02, -1.6846e-02, -1.8127e-02, -1.4191e-03,\n",
       "        -1.7658e-02, -7.6294e-03,  2.4475e-02,  2.1973e-02, -1.1597e-03,\n",
       "        -3.7781e-02,  1.0056e-02,  2.6367e-02, -7.5188e-03,  5.4688e-02,\n",
       "        -1.0773e-02,  2.2461e-02,  8.5754e-03, -2.5986e-02, -6.7139e-04,\n",
       "         4.4945e-02, -2.7283e-02,  1.3168e-02,  1.1414e-02,  4.9438e-03,\n",
       "         5.7678e-03,  2.5459e-02,  3.9124e-02,  3.0029e-02, -2.9175e-02,\n",
       "         2.0630e-02, -1.2329e-02,  9.2773e-03,  4.1962e-03, -1.6968e-02,\n",
       "        -3.3508e-02,  1.8311e-04,  5.2490e-03,  7.9346e-04, -2.7588e-02,\n",
       "         9.3079e-04, -2.3605e-02,  1.1597e-02,  8.8501e-04, -9.5215e-03,\n",
       "        -2.6611e-02, -4.2847e-02,  8.1787e-03, -2.4815e-02, -2.7222e-02,\n",
       "        -7.3853e-03, -2.2659e-02,  1.6407e-02, -7.2327e-03, -4.1199e-03,\n",
       "        -6.4096e-03,  1.8677e-02,  3.5400e-03,  1.0498e-02,  9.4910e-03,\n",
       "         1.4160e-02,  6.4056e-02, -8.6670e-03,  5.5161e-03, -1.6163e-02,\n",
       "        -5.2734e-02,  4.3945e-03, -3.1799e-02, -4.0894e-02,  2.8984e-02,\n",
       "         1.5266e-02,  1.8066e-02,  3.9429e-02,  4.3732e-02, -3.3081e-02,\n",
       "        -1.1948e-02,  1.9226e-03,  9.9487e-03, -5.3223e-02,  2.0081e-02,\n",
       "         2.1057e-02, -2.7100e-02, -3.0396e-02, -4.7302e-04,  1.0742e-02,\n",
       "        -2.1362e-04,  1.2924e-02, -3.8025e-02, -2.3315e-02, -2.0218e-02,\n",
       "        -3.3203e-02,  2.8946e-02,  2.1973e-02,  8.1177e-03, -9.9487e-03,\n",
       "         1.6876e-02,  3.4248e-02, -2.1484e-02, -4.8828e-03,  1.3885e-02,\n",
       "         2.0325e-02,  3.0884e-02, -1.0986e-02, -2.0630e-02,  3.6621e-04,\n",
       "        -1.2329e-02, -5.3223e-02,  2.9175e-02,  3.1967e-02,  1.4282e-02,\n",
       "         1.4526e-02,  1.6541e-02,  2.7897e-02, -8.6670e-03,  7.4463e-03,\n",
       "         2.6093e-03,  1.5106e-02, -7.2708e-03,  1.0376e-03,  1.9531e-02,\n",
       "         9.2773e-03,  3.0396e-02, -2.8076e-02,  4.9591e-03,  1.5773e-02,\n",
       "        -1.7609e-02, -1.5564e-02, -6.0177e-03, -2.2705e-02, -2.0111e-02,\n",
       "        -2.1973e-02, -4.1748e-02,  3.3691e-02, -3.0518e-04,  1.1536e-02,\n",
       "        -1.8921e-02, -2.8381e-02, -6.5918e-03,  9.1553e-05,  3.7109e-02,\n",
       "         9.0637e-03,  2.1240e-02, -2.4719e-02,  4.5288e-02,  1.1230e-02,\n",
       "        -3.6743e-02, -3.2898e-02], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data3 - encoded_data0 -encoded_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2143,  4.7596,  0.0000,  ...,  0.0000,  1.6853, 53.6174],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.0996e+02,  1.3838e+03, -2.7657e+02,  1.7381e+02, -8.0764e+02,\n",
       "        -4.4667e+02,  1.6538e+03, -3.3959e+02,  3.0095e+01, -1.0127e+03,\n",
       "        -8.0965e+02, -2.2723e+02, -1.1859e+02,  1.9088e+03,  7.7771e+02,\n",
       "         1.3478e+00, -9.8462e+02, -4.6163e+02,  3.8760e+02,  3.4913e+02,\n",
       "        -5.3808e+02,  1.0432e+03, -7.9333e+02, -5.8211e+01, -5.1734e+02,\n",
       "        -1.0182e+02,  3.0921e+02, -8.5020e+02,  7.4049e+02, -4.1386e+02,\n",
       "        -4.8993e+02,  6.4466e+02,  7.2970e+02, -4.6636e+02,  1.0676e+02,\n",
       "         8.7692e+02,  2.7649e+03, -5.6593e+02,  9.3169e+02, -4.4889e+02,\n",
       "        -1.3800e+02, -2.5234e+02,  1.2548e+03, -9.1330e+02,  7.3846e+02,\n",
       "        -1.1178e+03, -2.1298e+02,  3.7805e+02,  6.8760e+01,  1.6672e+03,\n",
       "        -1.3964e+03,  1.7100e+02, -3.6106e+01, -1.1435e+02,  8.4892e+01,\n",
       "         7.0213e+02, -7.0040e+00, -1.0834e+03,  3.9108e+02,  9.3170e+02,\n",
       "        -1.6041e+03, -7.5843e+02,  4.2016e+02,  1.1246e+03,  4.6138e+02,\n",
       "        -2.6019e+02,  3.0228e+03,  2.2010e+02,  1.7486e+02, -3.0369e+02,\n",
       "         7.4761e+01, -1.2341e+02, -2.5923e+02, -4.6946e+02, -6.9411e+02,\n",
       "         5.0514e+02, -1.3381e+02, -1.1945e+03,  5.5694e+02,  5.4725e+01,\n",
       "        -2.3797e+02, -1.0338e+03,  1.6442e+03,  1.1194e+02, -1.4464e+03,\n",
       "         4.6332e+02, -7.4965e+02, -8.6018e+02, -2.5089e+02, -3.7084e+02,\n",
       "         6.8574e+02,  1.9589e+02,  6.4075e+02, -1.7316e+02, -1.0573e+03,\n",
       "        -6.1822e+02,  6.4809e+02,  1.8706e+01, -2.6796e+02, -7.4779e+02,\n",
       "        -1.5997e+03, -5.7114e+02,  1.2469e+03, -7.3637e+01,  3.8891e+02,\n",
       "         7.2957e+02, -7.2163e+02, -8.8265e+02,  1.7285e+03,  1.0216e+03,\n",
       "        -3.5061e+02, -7.8338e+02, -9.2211e+02,  1.1214e+03, -6.6118e+02,\n",
       "        -7.2103e+02, -1.2483e+03,  1.2045e+03,  8.5785e+01,  3.3968e+02,\n",
       "         8.7532e+02, -1.3765e+03, -4.1824e+02, -8.9358e+02,  1.6136e+03,\n",
       "        -2.6396e+02,  4.1181e+02,  7.9774e+02,  1.4344e+02,  3.4507e+03,\n",
       "         7.7530e+02,  1.0185e+02,  2.3998e+03, -1.0055e+03,  4.7992e+02,\n",
       "        -2.2625e+02,  7.3804e+02,  3.3290e+02, -5.2862e+02,  4.3764e+02,\n",
       "        -7.0463e+02, -4.5378e+02,  9.1343e+02,  8.9091e+02,  1.1248e+03,\n",
       "        -6.4410e+02, -4.8017e+02, -2.5072e+01, -7.1698e+02, -5.9148e+01,\n",
       "        -3.1793e+02, -1.0910e+02,  1.5872e+02,  2.5470e+02, -2.2452e+02,\n",
       "         2.8880e+02, -9.1685e+02,  4.8818e+02, -1.7679e+03, -8.4994e+02,\n",
       "        -5.8364e+02,  1.1887e+03, -1.0776e+03, -1.1725e+03,  1.1659e+02,\n",
       "         1.0104e+03,  6.1199e+02,  2.0052e+03,  3.5880e+02, -3.6057e+02,\n",
       "         2.3194e+02, -3.7392e+02,  5.0738e+02, -1.3282e+03,  1.7183e+03,\n",
       "        -6.7353e+02, -1.5088e+02,  3.6446e+02, -5.3838e+01,  9.6248e+02,\n",
       "         1.1367e+03, -3.0945e+02,  5.0730e+01,  1.3147e+02,  3.3180e+01,\n",
       "         2.9855e+02, -3.2156e+02,  2.1162e+03, -7.1858e+02,  8.8719e+02,\n",
       "         2.6590e+02,  5.4196e+02, -8.8759e+02,  1.6450e+03,  3.6078e+02,\n",
       "        -4.1351e+02,  9.2316e+02, -2.0472e+02,  3.8072e+02, -2.9291e+02,\n",
       "        -1.1534e+03,  6.9546e-02, -5.6843e+02, -2.3188e+01,  1.1978e+02,\n",
       "         6.7658e+01,  8.6516e+01,  1.3004e+03, -7.5361e+02,  1.7482e+03,\n",
       "         1.7228e+03,  3.5880e+02,  1.7691e+02,  8.5896e+02, -5.8385e+02,\n",
       "         9.0032e+02,  3.4875e+02,  1.1144e+03,  1.0376e+03,  1.6389e+02,\n",
       "        -1.0733e+02,  3.9195e+02, -1.1230e+03, -6.7865e+02, -2.0609e+02,\n",
       "         3.8918e+01,  6.6118e+01, -4.9385e+01,  1.0510e+03,  3.5752e+01,\n",
       "         9.6165e+02,  2.2484e+02, -1.3335e+03,  8.4255e+02, -6.2359e+02,\n",
       "        -4.3954e+02,  3.9796e+02, -4.2121e+02,  1.0857e+03, -4.4630e+02,\n",
       "        -1.0590e+03,  7.3576e+02,  8.0570e+02, -1.3507e+03,  7.5577e+02,\n",
       "        -9.3830e+02, -1.8773e+02, -1.4386e+02, -2.6250e+02,  2.8150e+02,\n",
       "        -3.8554e+02,  7.2300e+02, -9.0453e+02, -5.8295e+02,  1.6978e+02,\n",
       "        -4.0966e+02,  1.4327e+02,  1.1044e+02, -9.2030e+01, -1.5762e+03,\n",
       "         2.3139e+02, -1.7803e+03,  3.3967e+02, -8.6982e+01,  1.2769e+03,\n",
       "        -5.4987e+02,  1.2009e+02, -6.7898e+02, -6.5265e+01, -1.9612e+02,\n",
       "        -5.3159e+02,  8.7193e+02,  4.1005e+02, -4.4212e+02, -7.7521e+01,\n",
       "         2.8615e+02, -1.1234e+02, -5.1900e+02, -7.6050e+02,  4.8309e+02,\n",
       "         6.4026e+02, -2.9192e+02,  1.4562e+03, -2.7186e+02, -3.8404e+02,\n",
       "        -4.5520e+02,  8.2379e+02,  2.0876e+03, -3.8027e+02, -4.4623e+02,\n",
       "        -1.2487e+03, -7.9663e+01, -4.0141e+01,  1.3115e+02, -1.9354e+03,\n",
       "        -2.2393e+03, -2.9332e+02, -8.1932e+02, -2.4376e+02, -2.5454e+02,\n",
       "         9.3700e+02,  8.7166e+01,  1.6591e+02,  1.7589e+03, -9.5419e+02,\n",
       "        -1.9014e+02,  5.1798e+02, -2.9486e+02,  2.5505e+02, -2.4520e+02,\n",
       "         3.0468e+03,  1.3770e+02,  2.7890e+02,  7.6402e+01, -3.1348e+01,\n",
       "        -1.4907e+02, -1.5420e+03, -1.5377e+03, -2.1880e+02,  2.1477e+02,\n",
       "         3.8352e+02, -1.4448e+02, -4.2101e+02, -3.2854e+02, -1.3583e+03,\n",
       "        -3.1862e+02,  2.7042e+02,  1.4208e+03,  4.7051e+02, -6.0217e+02,\n",
       "         1.3927e+03, -1.3778e+02, -4.7754e+02, -6.2827e+01, -1.4518e+02,\n",
       "        -4.7020e+02, -1.2678e+03, -1.1584e+02,  5.3644e+01,  1.3807e+03,\n",
       "        -6.6918e+02, -1.8450e+02,  7.4631e+02,  5.8283e+02, -1.4289e+02,\n",
       "         2.0538e+03, -9.3095e+02,  5.3654e+02,  1.0229e+03, -9.9434e+02,\n",
       "         9.9505e+02,  3.4673e+02,  1.3586e+03, -2.9105e+02,  1.8245e+02,\n",
       "         4.4597e+01, -8.9784e+02, -6.4857e+02,  1.3166e+03,  7.4997e+02,\n",
       "        -5.1390e+02,  8.7038e+01,  1.7545e+02,  4.0329e+03,  1.8535e+03,\n",
       "        -1.2846e+03, -1.3572e+03, -9.9692e+02,  8.9139e+02, -4.7341e+02,\n",
       "         2.3215e+01, -5.6595e+02, -6.1449e+02,  1.0254e+03, -5.2723e+02,\n",
       "         9.2319e+02,  4.8291e+02, -1.9782e+03, -1.4100e+02, -1.1871e+03,\n",
       "         5.3082e+02, -1.7926e+03,  2.4763e+02,  6.5322e+02, -1.4670e+03,\n",
       "         3.8440e+02,  1.1069e+03, -1.7154e+02,  4.2959e+02, -2.9053e+02,\n",
       "         9.2850e+02, -1.3803e+02, -5.0655e+02, -4.0830e+02,  1.4767e+03,\n",
       "        -6.6866e+02, -1.8600e+02, -1.6234e+03,  4.3027e+01, -6.5678e+02,\n",
       "         6.3551e+02,  1.3131e+03,  5.8988e+01,  4.3039e+02, -1.6989e+02,\n",
       "        -5.3558e+02, -2.5869e+02, -1.5766e+03, -2.1803e+02,  1.2515e+03,\n",
       "         3.2988e+02,  7.0818e+02, -6.0940e+02, -4.0693e+02, -1.3351e+03,\n",
       "         1.0495e+02, -1.1425e+02,  2.0745e+02, -5.2673e+02, -5.9963e+02,\n",
       "        -8.5435e+02, -9.6503e+02,  1.4136e+03, -6.9298e+02,  3.6586e+02,\n",
       "        -2.0547e+02, -1.8164e+02,  8.2828e+02, -5.4217e+02,  6.5334e+02,\n",
       "         2.4198e+03, -9.0069e+02,  3.0961e+02,  4.0446e+02,  3.8125e+02,\n",
       "         1.6702e+02, -5.2224e+02, -9.3761e+02, -1.6954e+02,  8.4652e+02,\n",
       "         7.8253e+02,  6.1872e+02,  1.0125e+03,  2.9744e+03, -5.6411e+02,\n",
       "        -7.8854e+02,  1.0572e+03, -9.3773e+02, -1.2932e+02, -2.3494e+03,\n",
       "         1.6827e+02,  2.5765e+00,  1.6289e+03,  8.6312e+01,  1.3163e+01,\n",
       "        -1.2253e+03, -3.5826e+02, -2.8715e+02, -9.1751e+00, -1.2886e+03,\n",
       "        -1.7897e+02,  7.7516e+01, -3.0281e+02,  1.0801e+03, -5.6181e+02,\n",
       "        -4.6138e+02,  3.6325e+02, -9.5546e+02,  1.0634e+03,  1.2537e+02,\n",
       "         4.8502e+01,  2.6771e+03,  7.0775e+02, -3.0877e+02, -1.3802e+03,\n",
       "        -7.4022e+02, -3.8279e+02, -5.9792e+02, -1.9648e+03,  4.0914e+02,\n",
       "        -6.9615e+02, -1.4269e+03,  3.1234e+02,  1.6219e+03,  6.9275e+02,\n",
       "        -7.1090e+02,  1.3095e+03,  1.4767e+03, -5.4248e+02, -3.3704e+01,\n",
       "        -4.2671e+02,  8.5612e+02, -5.5998e+01,  1.6209e+03, -1.5623e+02,\n",
       "        -1.7288e+03,  1.5882e+03, -2.8673e+03, -1.0945e+02, -6.2445e+01,\n",
       "         6.7293e+02,  8.3276e+02,  5.0813e+02, -2.8085e+01, -1.7284e+03,\n",
       "         1.5702e+03,  1.0131e+03,  6.7600e+02, -1.7925e+03, -1.7391e+03,\n",
       "         5.1809e+02,  1.5947e+02], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
